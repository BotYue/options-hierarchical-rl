{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-16 12:06:58,114] Making new env: Fourrooms-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 0 steps 101 cumreward 1.0 avg. duration                 3.12765957447 switches 47\n",
      "Run 0 episode 1 steps 145 cumreward 1.0 avg. duration                 2.89473684211 switches 76\n",
      "Run 0 episode 2 steps 348 cumreward 1.0 avg. duration                 3.25974025974 switches 154\n",
      "Run 0 episode 3 steps 24 cumreward 1.0 avg. duration                 3.0 switches 12\n",
      "Run 0 episode 4 steps 366 cumreward 1.0 avg. duration                 2.97297297297 switches 185\n",
      "Run 0 episode 5 steps 47 cumreward 1.0 avg. duration                 2.64285714286 switches 28\n",
      "Run 0 episode 6 steps 122 cumreward 1.0 avg. duration                 3.10526315789 switches 57\n",
      "Run 0 episode 7 steps 585 cumreward 1.0 avg. duration                 2.89935064935 switches 308\n",
      "Run 0 episode 8 steps 998 cumreward 1.0 avg. duration                 3.01209677419 switches 496\n",
      "Run 0 episode 9 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 10 steps 41 cumreward 1.0 avg. duration                 2.86363636364 switches 22\n",
      "Run 0 episode 11 steps 11 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 12 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 13 steps 17 cumreward 1.0 avg. duration                 2.77777777778 switches 9\n",
      "Run 0 episode 14 steps 17 cumreward 1.0 avg. duration                 3.125 switches 8\n",
      "Run 0 episode 15 steps 45 cumreward 1.0 avg. duration                 2.875 switches 24\n",
      "Run 0 episode 16 steps 56 cumreward 1.0 avg. duration                 2.71875 switches 32\n",
      "Run 0 episode 17 steps 42 cumreward 1.0 avg. duration                 3.625 switches 16\n",
      "Run 0 episode 18 steps 9 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 19 steps 31 cumreward 1.0 avg. duration                 2.66666666667 switches 18\n",
      "Run 0 episode 20 steps 218 cumreward 1.0 avg. duration                 2.98181818182 switches 110\n",
      "Run 0 episode 21 steps 7 cumreward 1.0 avg. duration                 4.5 switches 2\n",
      "Run 0 episode 22 steps 782 cumreward 1.0 avg. duration                 3.00512820513 switches 390\n",
      "Run 0 episode 23 steps 294 cumreward 1.0 avg. duration                 3.08510638298 switches 141\n",
      "Run 0 episode 24 steps 264 cumreward 1.0 avg. duration                 2.93333333333 switches 135\n",
      "Run 0 episode 25 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 26 steps 8 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 27 steps 31 cumreward 1.0 avg. duration                 2.5 switches 20\n",
      "Run 0 episode 28 steps 59 cumreward 1.0 avg. duration                 2.65714285714 switches 35\n",
      "Run 0 episode 29 steps 25 cumreward 1.0 avg. duration                 2.4 switches 15\n",
      "Run 0 episode 30 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 31 steps 396 cumreward 1.0 avg. duration                 3.0 switches 198\n",
      "Run 0 episode 32 steps 114 cumreward 1.0 avg. duration                 3.4347826087 switches 46\n",
      "Run 0 episode 33 steps 20 cumreward 1.0 avg. duration                 2.17647058824 switches 17\n",
      "Run 0 episode 34 steps 299 cumreward 1.0 avg. duration                 2.91612903226 switches 155\n",
      "Run 0 episode 35 steps 25 cumreward 1.0 avg. duration                 2.64285714286 switches 14\n",
      "Run 0 episode 36 steps 9 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 37 steps 7 cumreward 1.0 avg. duration                 2.0 switches 6\n",
      "Run 0 episode 38 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 39 steps 134 cumreward 1.0 avg. duration                 2.89855072464 switches 69\n",
      "Run 0 episode 40 steps 18 cumreward 1.0 avg. duration                 3.25 switches 8\n",
      "Run 0 episode 41 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 42 steps 9 cumreward 1.0 avg. duration                 5.5 switches 2\n",
      "Run 0 episode 43 steps 36 cumreward 1.0 avg. duration                 3.25 switches 16\n",
      "Run 0 episode 44 steps 15 cumreward 1.0 avg. duration                 3.5 switches 6\n",
      "Run 0 episode 45 steps 180 cumreward 1.0 avg. duration                 2.97802197802 switches 91\n",
      "Run 0 episode 46 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 47 steps 29 cumreward 1.0 avg. duration                 2.93333333333 switches 15\n",
      "Run 0 episode 48 steps 127 cumreward 1.0 avg. duration                 3.11666666667 switches 60\n",
      "Run 0 episode 49 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 50 steps 17 cumreward 1.0 avg. duration                 2.6 switches 10\n",
      "Run 0 episode 51 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 52 steps 36 cumreward 1.0 avg. duration                 2.83333333333 switches 18\n",
      "Run 0 episode 53 steps 7 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 54 steps 40 cumreward 1.0 avg. duration                 3.5 switches 16\n",
      "Run 0 episode 55 steps 2 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 56 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 57 steps 35 cumreward 1.0 avg. duration                 2.63157894737 switches 19\n",
      "Run 0 episode 58 steps 22 cumreward 1.0 avg. duration                 2.83333333333 switches 12\n",
      "Run 0 episode 59 steps 199 cumreward 1.0 avg. duration                 3.0306122449 switches 98\n",
      "Run 0 episode 60 steps 192 cumreward 1.0 avg. duration                 2.92 switches 100\n",
      "Run 0 episode 61 steps 13 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 62 steps 255 cumreward 1.0 avg. duration                 2.82142857143 switches 140\n",
      "Run 0 episode 63 steps 162 cumreward 1.0 avg. duration                 2.97530864198 switches 81\n",
      "Run 0 episode 64 steps 18 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 65 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 66 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 67 steps 43 cumreward 1.0 avg. duration                 3.27777777778 switches 18\n",
      "Run 0 episode 68 steps 19 cumreward 1.0 avg. duration                 2.35714285714 switches 14\n",
      "Run 0 episode 69 steps 6 cumreward 1.0 avg. duration                 6.0 switches 1\n",
      "Run 0 episode 70 steps 137 cumreward 1.0 avg. duration                 2.81333333333 switches 75\n",
      "Run 0 episode 71 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 72 steps 26 cumreward 1.0 avg. duration                 3.08333333333 switches 12\n",
      "Run 0 episode 73 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 74 steps 8 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 75 steps 4 cumreward 1.0 avg. duration                 5.0 switches 1\n",
      "Run 0 episode 76 steps 7 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 77 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 78 steps 5 cumreward 1.0 avg. duration                 1.8 switches 5\n",
      "Run 0 episode 79 steps 81 cumreward 1.0 avg. duration                 3.07692307692 switches 39\n",
      "Run 0 episode 80 steps 4 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 81 steps 60 cumreward 1.0 avg. duration                 2.66666666667 switches 36\n",
      "Run 0 episode 82 steps 20 cumreward 1.0 avg. duration                 4.8 switches 5\n",
      "Run 0 episode 83 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 84 steps 6 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 85 steps 9 cumreward 1.0 avg. duration                 3.25 switches 4\n",
      "Run 0 episode 86 steps 41 cumreward 1.0 avg. duration                 3.41176470588 switches 17\n",
      "Run 0 episode 87 steps 16 cumreward 1.0 avg. duration                 2.85714285714 switches 7\n",
      "Run 0 episode 88 steps 14 cumreward 1.0 avg. duration                 4.5 switches 4\n",
      "Run 0 episode 89 steps 88 cumreward 1.0 avg. duration                 3.04761904762 switches 42\n",
      "Run 0 episode 90 steps 8 cumreward 1.0 avg. duration                 3.66666666667 switches 3\n",
      "Run 0 episode 91 steps 4 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 92 steps 35 cumreward 1.0 avg. duration                 3.0625 switches 16\n",
      "Run 0 episode 93 steps 7 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 94 steps 14 cumreward 1.0 avg. duration                 2.4 switches 10\n",
      "Run 0 episode 95 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 96 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 97 steps 22 cumreward 1.0 avg. duration                 2.33333333333 switches 12\n",
      "Run 0 episode 98 steps 20 cumreward 1.0 avg. duration                 2.66666666667 switches 12\n",
      "Run 0 episode 99 steps 45 cumreward 1.0 avg. duration                 2.73076923077 switches 26\n",
      "Run 0 episode 100 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 101 steps 26 cumreward 1.0 avg. duration                 3.6 switches 10\n",
      "Run 0 episode 102 steps 28 cumreward 1.0 avg. duration                 3.0 switches 13\n",
      "Run 0 episode 103 steps 8 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 104 steps 33 cumreward 1.0 avg. duration                 3.53846153846 switches 13\n",
      "Run 0 episode 105 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 106 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 107 steps 30 cumreward 1.0 avg. duration                 2.45 switches 20\n",
      "Run 0 episode 108 steps 47 cumreward 1.0 avg. duration                 2.8 switches 25\n",
      "Run 0 episode 109 steps 6 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 110 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 111 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 112 steps 32 cumreward 1.0 avg. duration                 2.88235294118 switches 17\n",
      "Run 0 episode 113 steps 10 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 114 steps 22 cumreward 1.0 avg. duration                 3.33333333333 switches 6\n",
      "Run 0 episode 115 steps 20 cumreward 1.0 avg. duration                 2.42857142857 switches 14\n",
      "Run 0 episode 116 steps 11 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 117 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 118 steps 9 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 119 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 120 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 121 steps 8 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 122 steps 5 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 123 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 124 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 125 steps 13 cumreward 1.0 avg. duration                 2.5 switches 8\n",
      "Run 0 episode 126 steps 23 cumreward 1.0 avg. duration                 2.35294117647 switches 17\n",
      "Run 0 episode 127 steps 18 cumreward 1.0 avg. duration                 3.83333333333 switches 6\n",
      "Run 0 episode 128 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 129 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 130 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 131 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 132 steps 6 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 133 steps 6 cumreward 1.0 avg. duration                 2.0 switches 6\n",
      "Run 0 episode 134 steps 102 cumreward 1.0 avg. duration                 3.17021276596 switches 47\n",
      "Run 0 episode 135 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 136 steps 39 cumreward 1.0 avg. duration                 2.48 switches 25\n",
      "Run 0 episode 137 steps 24 cumreward 1.0 avg. duration                 3.09090909091 switches 11\n",
      "Run 0 episode 138 steps 22 cumreward 1.0 avg. duration                 2.69230769231 switches 13\n",
      "Run 0 episode 139 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 140 steps 14 cumreward 1.0 avg. duration                 2.4 switches 10\n",
      "Run 0 episode 141 steps 6 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 142 steps 6 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 143 steps 38 cumreward 1.0 avg. duration                 3.0 switches 17\n",
      "Run 0 episode 144 steps 11 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 145 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 146 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 147 steps 11 cumreward 1.0 avg. duration                 2.25 switches 8\n",
      "Run 0 episode 148 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 149 steps 1 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 150 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 151 steps 15 cumreward 1.0 avg. duration                 2.66666666667 switches 9\n",
      "Run 0 episode 152 steps 14 cumreward 1.0 avg. duration                 3.33333333333 switches 6\n",
      "Run 0 episode 153 steps 5 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 154 steps 7 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 155 steps 36 cumreward 1.0 avg. duration                 2.94444444444 switches 18\n",
      "Run 0 episode 156 steps 10 cumreward 1.0 avg. duration                 5.5 switches 2\n",
      "Run 0 episode 157 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 158 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 159 steps 14 cumreward 1.0 avg. duration                 2.27272727273 switches 11\n",
      "Run 0 episode 160 steps 7 cumreward 1.0 avg. duration                 2.0 switches 7\n",
      "Run 0 episode 161 steps 30 cumreward 1.0 avg. duration                 2.57894736842 switches 19\n",
      "Run 0 episode 162 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 163 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 164 steps 16 cumreward 1.0 avg. duration                 2.875 switches 8\n",
      "Run 0 episode 165 steps 5 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 166 steps 39 cumreward 1.0 avg. duration                 2.69565217391 switches 23\n",
      "Run 0 episode 167 steps 12 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 168 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 169 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 170 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 171 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 172 steps 13 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 173 steps 5 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 174 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 175 steps 10 cumreward 1.0 avg. duration                 2.11111111111 switches 9\n",
      "Run 0 episode 176 steps 18 cumreward 1.0 avg. duration                 2.5 switches 12\n",
      "Run 0 episode 177 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 178 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 179 steps 15 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 180 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 181 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 182 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 183 steps 14 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 184 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 185 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 186 steps 17 cumreward 1.0 avg. duration                 3.0 switches 8\n",
      "Run 0 episode 187 steps 13 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 188 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 189 steps 5 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 190 steps 35 cumreward 1.0 avg. duration                 3.53846153846 switches 13\n",
      "Run 0 episode 191 steps 3 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 192 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 193 steps 10 cumreward 1.0 avg. duration                 2.25 switches 8\n",
      "Run 0 episode 194 steps 12 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 195 steps 11 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 196 steps 4 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 197 steps 13 cumreward 1.0 avg. duration                 2.44444444444 switches 9\n",
      "Run 0 episode 198 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 199 steps 21 cumreward 1.0 avg. duration                 2.72727272727 switches 11\n",
      "Run 0 episode 200 steps 12 cumreward 1.0 avg. duration                 2.22222222222 switches 9\n",
      "Run 0 episode 201 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 202 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 203 steps 4 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 204 steps 3 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 205 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 206 steps 29 cumreward 1.0 avg. duration                 3.63636363636 switches 11\n",
      "Run 0 episode 207 steps 15 cumreward 1.0 avg. duration                 2.875 switches 8\n",
      "Run 0 episode 208 steps 1 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 209 steps 8 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 210 steps 12 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 211 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 212 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 213 steps 10 cumreward 1.0 avg. duration                 2.125 switches 8\n",
      "Run 0 episode 214 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 215 steps 11 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 216 steps 17 cumreward 1.0 avg. duration                 2.54545454545 switches 11\n",
      "Run 0 episode 217 steps 6 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 218 steps 28 cumreward 1.0 avg. duration                 2.26315789474 switches 19\n",
      "Run 0 episode 219 steps 13 cumreward 1.0 avg. duration                 3.0 switches 6\n",
      "Run 0 episode 220 steps 9 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 221 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 222 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 223 steps 27 cumreward 1.0 avg. duration                 2.92307692308 switches 13\n",
      "Run 0 episode 224 steps 15 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 225 steps 25 cumreward 1.0 avg. duration                 2.71428571429 switches 14\n",
      "Run 0 episode 226 steps 8 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 227 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 228 steps 5 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 229 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 230 steps 2 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 231 steps 12 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 232 steps 6 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 233 steps 24 cumreward 1.0 avg. duration                 3.18181818182 switches 11\n",
      "Run 0 episode 234 steps 11 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 235 steps 20 cumreward 1.0 avg. duration                 2.28571428571 switches 14\n",
      "Run 0 episode 236 steps 10 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 237 steps 12 cumreward 1.0 avg. duration                 2.2 switches 10\n",
      "Run 0 episode 238 steps 13 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 239 steps 13 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 240 steps 20 cumreward 1.0 avg. duration                 2.7 switches 10\n",
      "Run 0 episode 241 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 242 steps 16 cumreward 1.0 avg. duration                 3.5 switches 6\n",
      "Run 0 episode 243 steps 4 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 244 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 245 steps 28 cumreward 1.0 avg. duration                 3.15384615385 switches 13\n",
      "Run 0 episode 246 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 247 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 248 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 249 steps 10 cumreward 1.0 avg. duration                 2.25 switches 8\n",
      "Run 0 episode 250 steps 6 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 251 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 252 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 253 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 254 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 255 steps 9 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 256 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 257 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 258 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 259 steps 13 cumreward 1.0 avg. duration                 2.85714285714 switches 7\n",
      "Run 0 episode 260 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 261 steps 10 cumreward 1.0 avg. duration                 1.90909090909 switches 11\n",
      "Run 0 episode 262 steps 18 cumreward 1.0 avg. duration                 2.63636363636 switches 11\n",
      "Run 0 episode 263 steps 5 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 264 steps 17 cumreward 1.0 avg. duration                 2.88888888889 switches 9\n",
      "Run 0 episode 265 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 266 steps 10 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 267 steps 10 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 268 steps 12 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 269 steps 5 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 270 steps 14 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 271 steps 9 cumreward 1.0 avg. duration                 4.0 switches 3\n",
      "Run 0 episode 272 steps 22 cumreward 1.0 avg. duration                 3.625 switches 8\n",
      "Run 0 episode 273 steps 19 cumreward 1.0 avg. duration                 2.58333333333 switches 12\n",
      "Run 0 episode 274 steps 12 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 275 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 276 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 277 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 278 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 279 steps 13 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 280 steps 21 cumreward 1.0 avg. duration                 2.90909090909 switches 11\n",
      "Run 0 episode 281 steps 22 cumreward 1.0 avg. duration                 3.0 switches 11\n",
      "Run 0 episode 282 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 283 steps 11 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 284 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 285 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 286 steps 12 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 287 steps 15 cumreward 1.0 avg. duration                 2.44444444444 switches 9\n",
      "Run 0 episode 288 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 289 steps 8 cumreward 1.0 avg. duration                 2.14285714286 switches 7\n",
      "Run 0 episode 290 steps 10 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 291 steps 12 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 292 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 293 steps 8 cumreward 1.0 avg. duration                 2.2 switches 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 294 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 295 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 296 steps 5 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 297 steps 3 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 298 steps 20 cumreward 1.0 avg. duration                 2.58333333333 switches 12\n",
      "Run 0 episode 299 steps 13 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 300 steps 18 cumreward 1.0 avg. duration                 3.14285714286 switches 7\n",
      "Run 0 episode 301 steps 13 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 302 steps 9 cumreward 1.0 avg. duration                 2.125 switches 8\n",
      "Run 0 episode 303 steps 10 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 304 steps 9 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 305 steps 5 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 306 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 307 steps 9 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 308 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 309 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 310 steps 18 cumreward 1.0 avg. duration                 2.7 switches 10\n",
      "Run 0 episode 311 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 312 steps 4 cumreward 1.0 avg. duration                 5.0 switches 1\n",
      "Run 0 episode 313 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 314 steps 11 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 315 steps 4 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 316 steps 6 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 317 steps 17 cumreward 1.0 avg. duration                 2.27272727273 switches 11\n",
      "Run 0 episode 318 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 319 steps 27 cumreward 1.0 avg. duration                 3.16666666667 switches 12\n",
      "Run 0 episode 320 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 321 steps 5 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 322 steps 12 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 323 steps 5 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 324 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 325 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 326 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 327 steps 7 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 328 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 329 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 330 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 331 steps 13 cumreward 1.0 avg. duration                 2.85714285714 switches 7\n",
      "Run 0 episode 332 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 333 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 334 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 335 steps 11 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 336 steps 14 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 337 steps 2 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 338 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 339 steps 4 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 340 steps 3 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 341 steps 3 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 342 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 343 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 344 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 345 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 346 steps 6 cumreward 1.0 avg. duration                 1.83333333333 switches 6\n",
      "Run 0 episode 347 steps 13 cumreward 1.0 avg. duration                 2.44444444444 switches 9\n",
      "Run 0 episode 348 steps 10 cumreward 1.0 avg. duration                 2.25 switches 8\n",
      "Run 0 episode 349 steps 17 cumreward 1.0 avg. duration                 2.30769230769 switches 13\n",
      "Run 0 episode 350 steps 7 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 351 steps 17 cumreward 1.0 avg. duration                 2.54545454545 switches 11\n",
      "Run 0 episode 352 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 353 steps 15 cumreward 1.0 avg. duration                 2.5 switches 10\n",
      "Run 0 episode 354 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 355 steps 24 cumreward 1.0 avg. duration                 2.5 switches 16\n",
      "Run 0 episode 356 steps 14 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 357 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 358 steps 15 cumreward 1.0 avg. duration                 3.14285714286 switches 7\n",
      "Run 0 episode 359 steps 17 cumreward 1.0 avg. duration                 2.7 switches 10\n",
      "Run 0 episode 360 steps 5 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 361 steps 8 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 362 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 363 steps 17 cumreward 1.0 avg. duration                 2.45454545455 switches 11\n",
      "Run 0 episode 364 steps 7 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 365 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 366 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 367 steps 12 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 368 steps 6 cumreward 1.0 avg. duration                 5.0 switches 1\n",
      "Run 0 episode 369 steps 14 cumreward 1.0 avg. duration                 3.0 switches 6\n",
      "Run 0 episode 370 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 371 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 372 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 373 steps 4 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 374 steps 5 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 375 steps 10 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 376 steps 14 cumreward 1.0 avg. duration                 2.55555555556 switches 9\n",
      "Run 0 episode 377 steps 8 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 378 steps 18 cumreward 1.0 avg. duration                 2.33333333333 switches 12\n",
      "Run 0 episode 379 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 380 steps 6 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 381 steps 23 cumreward 1.0 avg. duration                 3.2 switches 10\n",
      "Run 0 episode 382 steps 10 cumreward 1.0 avg. duration                 2.125 switches 8\n",
      "Run 0 episode 383 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 384 steps 13 cumreward 1.0 avg. duration                 2.85714285714 switches 7\n",
      "Run 0 episode 385 steps 3 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 386 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 387 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 388 steps 13 cumreward 1.0 avg. duration                 2.5 switches 8\n",
      "Run 0 episode 389 steps 8 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 390 steps 14 cumreward 1.0 avg. duration                 3.0 switches 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 391 steps 4 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 392 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 393 steps 9 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 394 steps 9 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 395 steps 10 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 396 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 397 steps 5 cumreward 1.0 avg. duration                 3.5 switches 2\n",
      "Run 0 episode 398 steps 11 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 399 steps 8 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 400 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 401 steps 14 cumreward 1.0 avg. duration                 2.75 switches 8\n",
      "Run 0 episode 402 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 403 steps 12 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 404 steps 8 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 405 steps 10 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 406 steps 12 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 407 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 408 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 409 steps 4 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 410 steps 3 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 411 steps 12 cumreward 1.0 avg. duration                 2.11111111111 switches 9\n",
      "Run 0 episode 412 steps 10 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 413 steps 5 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 414 steps 26 cumreward 1.0 avg. duration                 2.73333333333 switches 15\n",
      "Run 0 episode 415 steps 8 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 416 steps 22 cumreward 1.0 avg. duration                 2.6 switches 10\n",
      "Run 0 episode 417 steps 7 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 418 steps 4 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 419 steps 16 cumreward 1.0 avg. duration                 2.5 switches 10\n",
      "Run 0 episode 420 steps 2 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 421 steps 12 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 422 steps 16 cumreward 1.0 avg. duration                 3.4 switches 5\n",
      "Run 0 episode 423 steps 9 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 424 steps 8 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 425 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 426 steps 16 cumreward 1.0 avg. duration                 2.85714285714 switches 7\n",
      "Run 0 episode 427 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 428 steps 13 cumreward 1.0 avg. duration                 2.2 switches 10\n",
      "Run 0 episode 429 steps 8 cumreward 1.0 avg. duration                 4.5 switches 2\n",
      "Run 0 episode 430 steps 6 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 431 steps 9 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 432 steps 20 cumreward 1.0 avg. duration                 2.41666666667 switches 12\n",
      "Run 0 episode 433 steps 6 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 434 steps 14 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 435 steps 9 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 436 steps 7 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 437 steps 12 cumreward 1.0 avg. duration                 2.22222222222 switches 9\n",
      "Run 0 episode 438 steps 4 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 439 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 440 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 441 steps 11 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 442 steps 6 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 443 steps 6 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 444 steps 14 cumreward 1.0 avg. duration                 2.55555555556 switches 9\n",
      "Run 0 episode 445 steps 13 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 446 steps 8 cumreward 1.0 avg. duration                 1.8 switches 5\n",
      "Run 0 episode 447 steps 8 cumreward 1.0 avg. duration                 4.5 switches 2\n",
      "Run 0 episode 448 steps 8 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 449 steps 10 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 450 steps 12 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 451 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 452 steps 10 cumreward 1.0 avg. duration                 2.25 switches 8\n",
      "Run 0 episode 453 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 454 steps 10 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 455 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 456 steps 13 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 457 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 458 steps 12 cumreward 1.0 avg. duration                 3.0 switches 6\n",
      "Run 0 episode 459 steps 5 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 460 steps 14 cumreward 1.0 avg. duration                 3.33333333333 switches 6\n",
      "Run 0 episode 461 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 462 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 463 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 464 steps 7 cumreward 1.0 avg. duration                 7.0 switches 1\n",
      "Run 0 episode 465 steps 7 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 466 steps 15 cumreward 1.0 avg. duration                 2.66666666667 switches 9\n",
      "Run 0 episode 467 steps 7 cumreward 1.0 avg. duration                 2.0 switches 6\n",
      "Run 0 episode 468 steps 13 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 469 steps 8 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 470 steps 4 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 471 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 472 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 473 steps 7 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 474 steps 10 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 475 steps 9 cumreward 1.0 avg. duration                 2.0 switches 9\n",
      "Run 0 episode 476 steps 11 cumreward 1.0 avg. duration                 9.0 switches 1\n",
      "Run 0 episode 477 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 478 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 479 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 480 steps 4 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 481 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 482 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 483 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 484 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 485 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 486 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 487 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 488 steps 10 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 489 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 490 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 491 steps 6 cumreward 1.0 avg. duration                 4.0 switches 2\n",
      "Run 0 episode 492 steps 10 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 493 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 494 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 495 steps 20 cumreward 1.0 avg. duration                 2.81818181818 switches 11\n",
      "Run 0 episode 496 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 497 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 498 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 499 steps 14 cumreward 1.0 avg. duration                 3.33333333333 switches 6\n",
      "Run 0 episode 500 steps 7 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 501 steps 16 cumreward 1.0 avg. duration                 2.66666666667 switches 9\n",
      "Run 0 episode 502 steps 6 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 503 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 504 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 505 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 506 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 507 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 508 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 509 steps 6 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 510 steps 9 cumreward 1.0 avg. duration                 5.0 switches 2\n",
      "Run 0 episode 511 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 512 steps 9 cumreward 1.0 avg. duration                 3.25 switches 4\n",
      "Run 0 episode 513 steps 7 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 514 steps 7 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 515 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 516 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 517 steps 9 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 518 steps 13 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 519 steps 9 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 520 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 521 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 522 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 523 steps 9 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 524 steps 9 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 525 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 526 steps 3 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 527 steps 9 cumreward 1.0 avg. duration                 2.125 switches 8\n",
      "Run 0 episode 528 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 529 steps 13 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 530 steps 13 cumreward 1.0 avg. duration                 3.0 switches 6\n",
      "Run 0 episode 531 steps 7 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 532 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 533 steps 6 cumreward 1.0 avg. duration                 5.0 switches 1\n",
      "Run 0 episode 534 steps 12 cumreward 1.0 avg. duration                 3.0 switches 6\n",
      "Run 0 episode 535 steps 11 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 536 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 537 steps 11 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 538 steps 3 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 539 steps 2 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 540 steps 8 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 541 steps 12 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 542 steps 13 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 543 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 544 steps 7 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 545 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 546 steps 7 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 547 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 548 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 549 steps 19 cumreward 1.0 avg. duration                 3.125 switches 8\n",
      "Run 0 episode 550 steps 17 cumreward 1.0 avg. duration                 2.75 switches 8\n",
      "Run 0 episode 551 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 552 steps 8 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 553 steps 12 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 554 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 555 steps 7 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 556 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 557 steps 13 cumreward 1.0 avg. duration                 4.66666666667 switches 3\n",
      "Run 0 episode 558 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 559 steps 9 cumreward 1.0 avg. duration                 3.25 switches 4\n",
      "Run 0 episode 560 steps 4 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 561 steps 6 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 562 steps 8 cumreward 1.0 avg. duration                 3.66666666667 switches 3\n",
      "Run 0 episode 563 steps 5 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 564 steps 11 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 565 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 566 steps 4 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 567 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 568 steps 10 cumreward 1.0 avg. duration                 4.33333333333 switches 3\n",
      "Run 0 episode 569 steps 4 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 570 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 571 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 572 steps 4 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 573 steps 17 cumreward 1.0 avg. duration                 2.54545454545 switches 11\n",
      "Run 0 episode 574 steps 7 cumreward 1.0 avg. duration                 2.0 switches 6\n",
      "Run 0 episode 575 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 576 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 577 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 578 steps 2 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 579 steps 8 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 580 steps 11 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 581 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 582 steps 4 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 583 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 584 steps 13 cumreward 1.0 avg. duration                 3.6 switches 5\n",
      "Run 0 episode 585 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 586 steps 18 cumreward 1.0 avg. duration                 2.8 switches 10\n",
      "Run 0 episode 587 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 588 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 589 steps 5 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 590 steps 3 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 591 steps 19 cumreward 1.0 avg. duration                 2.26666666667 switches 15\n",
      "Run 0 episode 592 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 593 steps 6 cumreward 1.0 avg. duration                 1.85714285714 switches 7\n",
      "Run 0 episode 594 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 595 steps 7 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 596 steps 14 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 597 steps 18 cumreward 1.0 avg. duration                 2.8 switches 10\n",
      "Run 0 episode 598 steps 12 cumreward 1.0 avg. duration                 2.2 switches 10\n",
      "Run 0 episode 599 steps 18 cumreward 1.0 avg. duration                 2.63636363636 switches 11\n",
      "Run 0 episode 600 steps 7 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 601 steps 20 cumreward 1.0 avg. duration                 3.22222222222 switches 9\n",
      "Run 0 episode 602 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 603 steps 9 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 604 steps 8 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 605 steps 14 cumreward 1.0 avg. duration                 2.75 switches 8\n",
      "Run 0 episode 606 steps 13 cumreward 1.0 avg. duration                 7.5 switches 2\n",
      "Run 0 episode 607 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 608 steps 6 cumreward 1.0 avg. duration                 7.0 switches 1\n",
      "Run 0 episode 609 steps 14 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 610 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 611 steps 4 cumreward 1.0 avg. duration                 1.75 switches 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 612 steps 13 cumreward 1.0 avg. duration                 3.4 switches 5\n",
      "Run 0 episode 613 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 614 steps 9 cumreward 1.0 avg. duration                 10.0 switches 1\n",
      "Run 0 episode 615 steps 9 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 616 steps 13 cumreward 1.0 avg. duration                 3.4 switches 5\n",
      "Run 0 episode 617 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 618 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 619 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 620 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 621 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 622 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 623 steps 12 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 624 steps 9 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 625 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 626 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 627 steps 8 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 628 steps 18 cumreward 1.0 avg. duration                 3.25 switches 8\n",
      "Run 0 episode 629 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 630 steps 14 cumreward 1.0 avg. duration                 2.75 switches 8\n",
      "Run 0 episode 631 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 632 steps 6 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 633 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 634 steps 5 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 635 steps 13 cumreward 1.0 avg. duration                 3.6 switches 5\n",
      "Run 0 episode 636 steps 9 cumreward 1.0 avg. duration                 2.14285714286 switches 7\n",
      "Run 0 episode 637 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 638 steps 2 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 639 steps 12 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 640 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 641 steps 5 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 642 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 643 steps 19 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 644 steps 6 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 645 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 646 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 647 steps 14 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 648 steps 7 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 649 steps 12 cumreward 1.0 avg. duration                 2.5 switches 8\n",
      "Run 0 episode 650 steps 12 cumreward 1.0 avg. duration                 3.75 switches 4\n",
      "Run 0 episode 651 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 652 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 653 steps 6 cumreward 1.0 avg. duration                 1.85714285714 switches 7\n",
      "Run 0 episode 654 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 655 steps 15 cumreward 1.0 avg. duration                 2.75 switches 8\n",
      "Run 0 episode 656 steps 8 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 657 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 658 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 659 steps 8 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 660 steps 7 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 661 steps 18 cumreward 1.0 avg. duration                 2.77777777778 switches 9\n",
      "Run 0 episode 662 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 663 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 664 steps 7 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 665 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 666 steps 10 cumreward 1.0 avg. duration                 4.0 switches 3\n",
      "Run 0 episode 667 steps 3 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 668 steps 10 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 669 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 670 steps 21 cumreward 1.0 avg. duration                 3.1 switches 10\n",
      "Run 0 episode 671 steps 12 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 672 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 673 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 674 steps 10 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 675 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 676 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 677 steps 8 cumreward 1.0 avg. duration                 3.66666666667 switches 3\n",
      "Run 0 episode 678 steps 2 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 679 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 680 steps 11 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 681 steps 4 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 682 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 683 steps 17 cumreward 1.0 avg. duration                 3.42857142857 switches 7\n",
      "Run 0 episode 684 steps 16 cumreward 1.0 avg. duration                 3.0 switches 8\n",
      "Run 0 episode 685 steps 7 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 686 steps 4 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 687 steps 11 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 688 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 689 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 690 steps 12 cumreward 1.0 avg. duration                 2.33333333333 switches 9\n",
      "Run 0 episode 691 steps 14 cumreward 1.0 avg. duration                 2.4 switches 10\n",
      "Run 0 episode 692 steps 7 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 693 steps 4 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 694 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 695 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 696 steps 5 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 697 steps 15 cumreward 1.0 avg. duration                 4.0 switches 5\n",
      "Run 0 episode 698 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 699 steps 14 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 700 steps 13 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 701 steps 6 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 702 steps 14 cumreward 1.0 avg. duration                 3.6 switches 5\n",
      "Run 0 episode 703 steps 17 cumreward 1.0 avg. duration                 4.2 switches 5\n",
      "Run 0 episode 704 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 705 steps 13 cumreward 1.0 avg. duration                 2.22222222222 switches 9\n",
      "Run 0 episode 706 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 707 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 708 steps 5 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 709 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 710 steps 4 cumreward 1.0 avg. duration                 1.8 switches 5\n",
      "Run 0 episode 711 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 712 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 713 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 714 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 715 steps 1 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 716 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 717 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 718 steps 6 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 719 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 720 steps 3 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 721 steps 16 cumreward 1.0 avg. duration                 2.77777777778 switches 9\n",
      "Run 0 episode 722 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 723 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 724 steps 9 cumreward 1.0 avg. duration                 2.4 switches 5\n",
      "Run 0 episode 725 steps 7 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 726 steps 10 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 727 steps 6 cumreward 1.0 avg. duration                 4.0 switches 2\n",
      "Run 0 episode 728 steps 8 cumreward 1.0 avg. duration                 2.14285714286 switches 7\n",
      "Run 0 episode 729 steps 12 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 730 steps 16 cumreward 1.0 avg. duration                 3.0 switches 6\n",
      "Run 0 episode 731 steps 9 cumreward 1.0 avg. duration                 5.5 switches 2\n",
      "Run 0 episode 732 steps 2 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 733 steps 7 cumreward 1.0 avg. duration                 2.0 switches 6\n",
      "Run 0 episode 734 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 735 steps 6 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 736 steps 9 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 737 steps 6 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 738 steps 10 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 739 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 740 steps 10 cumreward 1.0 avg. duration                 4.0 switches 3\n",
      "Run 0 episode 741 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 742 steps 8 cumreward 1.0 avg. duration                 3.66666666667 switches 3\n",
      "Run 0 episode 743 steps 13 cumreward 1.0 avg. duration                 2.85714285714 switches 7\n",
      "Run 0 episode 744 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 745 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 746 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 747 steps 11 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 748 steps 4 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 749 steps 3 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 750 steps 9 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 751 steps 9 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 752 steps 9 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 753 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 754 steps 14 cumreward 1.0 avg. duration                 2.44444444444 switches 9\n",
      "Run 0 episode 755 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 756 steps 11 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 757 steps 3 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 758 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 759 steps 6 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 760 steps 9 cumreward 1.0 avg. duration                 4.0 switches 3\n",
      "Run 0 episode 761 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 762 steps 5 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 763 steps 19 cumreward 1.0 avg. duration                 3.28571428571 switches 7\n",
      "Run 0 episode 764 steps 6 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 765 steps 12 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 766 steps 9 cumreward 1.0 avg. duration                 3.5 switches 2\n",
      "Run 0 episode 767 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 768 steps 13 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 769 steps 9 cumreward 1.0 avg. duration                 5.0 switches 2\n",
      "Run 0 episode 770 steps 7 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 771 steps 8 cumreward 1.0 avg. duration                 3.33333333333 switches 3\n",
      "Run 0 episode 772 steps 15 cumreward 1.0 avg. duration                 3.14285714286 switches 7\n",
      "Run 0 episode 773 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 774 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 775 steps 4 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 776 steps 13 cumreward 1.0 avg. duration                 2.85714285714 switches 7\n",
      "Run 0 episode 777 steps 11 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 778 steps 7 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 779 steps 2 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 780 steps 7 cumreward 1.0 avg. duration                 5.0 switches 1\n",
      "Run 0 episode 781 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 782 steps 11 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 783 steps 13 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 784 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 785 steps 15 cumreward 1.0 avg. duration                 2.36363636364 switches 11\n",
      "Run 0 episode 786 steps 3 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 787 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 788 steps 10 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 789 steps 8 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 790 steps 6 cumreward 1.0 avg. duration                 4.0 switches 2\n",
      "Run 0 episode 791 steps 6 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 792 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 793 steps 15 cumreward 1.0 avg. duration                 3.33333333333 switches 6\n",
      "Run 0 episode 794 steps 14 cumreward 1.0 avg. duration                 2.75 switches 8\n",
      "Run 0 episode 795 steps 8 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 796 steps 6 cumreward 1.0 avg. duration                 4.0 switches 2\n",
      "Run 0 episode 797 steps 3 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 798 steps 16 cumreward 1.0 avg. duration                 3.0 switches 7\n",
      "Run 0 episode 799 steps 10 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 800 steps 8 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 801 steps 4 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 802 steps 6 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 803 steps 6 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 804 steps 5 cumreward 1.0 avg. duration                 5.0 switches 1\n",
      "Run 0 episode 805 steps 9 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 806 steps 3 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 807 steps 4 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 808 steps 14 cumreward 1.0 avg. duration                 3.0 switches 7\n",
      "Run 0 episode 809 steps 8 cumreward 1.0 avg. duration                 3.66666666667 switches 3\n",
      "Run 0 episode 810 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 811 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 812 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 813 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 814 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 815 steps 4 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 816 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 817 steps 11 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 818 steps 4 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 819 steps 4 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 820 steps 18 cumreward 1.0 avg. duration                 2.54545454545 switches 11\n",
      "Run 0 episode 821 steps 3 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 822 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 823 steps 13 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 824 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 825 steps 11 cumreward 1.0 avg. duration                 2.14285714286 switches 7\n",
      "Run 0 episode 826 steps 8 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 827 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 828 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 829 steps 6 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 830 steps 9 cumreward 1.0 avg. duration                 2.14285714286 switches 7\n",
      "Run 0 episode 831 steps 10 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 832 steps 6 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 833 steps 13 cumreward 1.0 avg. duration                 4.0 switches 3\n",
      "Run 0 episode 834 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 835 steps 6 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 836 steps 8 cumreward 1.0 avg. duration                 2.14285714286 switches 7\n",
      "Run 0 episode 837 steps 10 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 838 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 839 steps 10 cumreward 1.0 avg. duration                 3.66666666667 switches 3\n",
      "Run 0 episode 840 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 841 steps 12 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 842 steps 11 cumreward 1.0 avg. duration                 4.33333333333 switches 3\n",
      "Run 0 episode 843 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 844 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 845 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 846 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 847 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 848 steps 15 cumreward 1.0 avg. duration                 2.16666666667 switches 12\n",
      "Run 0 episode 849 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 850 steps 9 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 851 steps 9 cumreward 1.0 avg. duration                 2.0 switches 7\n",
      "Run 0 episode 852 steps 6 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 853 steps 12 cumreward 1.0 avg. duration                 2.5 switches 8\n",
      "Run 0 episode 854 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 855 steps 6 cumreward 1.0 avg. duration                 3.5 switches 2\n",
      "Run 0 episode 856 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 857 steps 12 cumreward 1.0 avg. duration                 2.8 switches 5\n",
      "Run 0 episode 858 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 859 steps 6 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 860 steps 7 cumreward 1.0 avg. duration                 2.0 switches 7\n",
      "Run 0 episode 861 steps 4 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 862 steps 15 cumreward 1.0 avg. duration                 3.5 switches 6\n",
      "Run 0 episode 863 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 864 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 865 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 866 steps 13 cumreward 1.0 avg. duration                 2.18181818182 switches 11\n",
      "Run 0 episode 867 steps 10 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 868 steps 11 cumreward 1.0 avg. duration                 2.83333333333 switches 6\n",
      "Run 0 episode 869 steps 9 cumreward 1.0 avg. duration                 2.28571428571 switches 7\n",
      "Run 0 episode 870 steps 9 cumreward 1.0 avg. duration                 3.25 switches 4\n",
      "Run 0 episode 871 steps 10 cumreward 1.0 avg. duration                 2.125 switches 8\n",
      "Run 0 episode 872 steps 7 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 873 steps 6 cumreward 1.0 avg. duration                 2.0 switches 5\n",
      "Run 0 episode 874 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 875 steps 9 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 876 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 877 steps 6 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 878 steps 2 cumreward 1.0 avg. duration                 1.66666666667 switches 3\n",
      "Run 0 episode 879 steps 10 cumreward 1.0 avg. duration                 2.66666666667 switches 6\n",
      "Run 0 episode 880 steps 1 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 881 steps 17 cumreward 1.0 avg. duration                 2.41666666667 switches 12\n",
      "Run 0 episode 882 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 883 steps 18 cumreward 1.0 avg. duration                 3.66666666667 switches 6\n",
      "Run 0 episode 884 steps 17 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 885 steps 3 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 886 steps 8 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 887 steps 0 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 888 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 889 steps 15 cumreward 1.0 avg. duration                 2.36363636364 switches 11\n",
      "Run 0 episode 890 steps 6 cumreward 1.0 avg. duration                 2.0 switches 6\n",
      "Run 0 episode 891 steps 8 cumreward 1.0 avg. duration                 3.5 switches 2\n",
      "Run 0 episode 892 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 893 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 894 steps 14 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 895 steps 11 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 896 steps 3 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 897 steps 10 cumreward 1.0 avg. duration                 2.16666666667 switches 6\n",
      "Run 0 episode 898 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 899 steps 10 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 900 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 901 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 902 steps 15 cumreward 1.0 avg. duration                 2.875 switches 8\n",
      "Run 0 episode 903 steps 3 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 904 steps 9 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 905 steps 14 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 906 steps 2 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 907 steps 1 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 908 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 909 steps 5 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 910 steps 7 cumreward 1.0 avg. duration                 2.5 switches 4\n",
      "Run 0 episode 911 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 912 steps 6 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 913 steps 15 cumreward 1.0 avg. duration                 2.15384615385 switches 13\n",
      "Run 0 episode 914 steps 21 cumreward 1.0 avg. duration                 2.90909090909 switches 11\n",
      "Run 0 episode 915 steps 13 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 916 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 917 steps 6 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 918 steps 9 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 919 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 920 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 921 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 922 steps 15 cumreward 1.0 avg. duration                 2.375 switches 8\n",
      "Run 0 episode 923 steps 1 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 924 steps 14 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 925 steps 4 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 926 steps 2 cumreward 1.0 avg. duration                 1.5 switches 2\n",
      "Run 0 episode 927 steps 1 cumreward 1.0 avg. duration                 2.0 switches 1\n",
      "Run 0 episode 928 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 929 steps 15 cumreward 1.0 avg. duration                 2.5 switches 10\n",
      "Run 0 episode 930 steps 3 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 931 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 932 steps 8 cumreward 1.0 avg. duration                 3.0 switches 4\n",
      "Run 0 episode 933 steps 3 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 934 steps 11 cumreward 1.0 avg. duration                 3.2 switches 5\n",
      "Run 0 episode 935 steps 23 cumreward 1.0 avg. duration                 3.3 switches 10\n",
      "Run 0 episode 936 steps 11 cumreward 1.0 avg. duration                 3.75 switches 4\n",
      "Run 0 episode 937 steps 11 cumreward 1.0 avg. duration                 4.0 switches 2\n",
      "Run 0 episode 938 steps 3 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 939 steps 17 cumreward 1.0 avg. duration                 2.33333333333 switches 12\n",
      "Run 0 episode 940 steps 9 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 941 steps 8 cumreward 1.0 avg. duration                 2.6 switches 5\n",
      "Run 0 episode 942 steps 9 cumreward 1.0 avg. duration                 2.14285714286 switches 7\n",
      "Run 0 episode 943 steps 12 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 944 steps 1 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 945 steps 0 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 946 steps 11 cumreward 1.0 avg. duration                 2.5 switches 6\n",
      "Run 0 episode 947 steps 10 cumreward 1.0 avg. duration                 3.5 switches 4\n",
      "Run 0 episode 948 steps 13 cumreward 1.0 avg. duration                 3.6 switches 5\n",
      "Run 0 episode 949 steps 13 cumreward 1.0 avg. duration                 2.625 switches 8\n",
      "Run 0 episode 950 steps 11 cumreward 1.0 avg. duration                 2.0 switches 7\n",
      "Run 0 episode 951 steps 2 cumreward 1.0 avg. duration                 1.0 switches 1\n",
      "Run 0 episode 952 steps 12 cumreward 1.0 avg. duration                 2.5 switches 8\n",
      "Run 0 episode 953 steps 6 cumreward 1.0 avg. duration                 2.2 switches 5\n",
      "Run 0 episode 954 steps 6 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 955 steps 4 cumreward 1.0 avg. duration                 1.75 switches 4\n",
      "Run 0 episode 956 steps 5 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 957 steps 5 cumreward 1.0 avg. duration                 3.0 switches 1\n",
      "Run 0 episode 958 steps 5 cumreward 1.0 avg. duration                 3.5 switches 2\n",
      "Run 0 episode 959 steps 1 cumreward 1.0 avg. duration                 0.0 switches 0\n",
      "Run 0 episode 960 steps 12 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 961 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 962 steps 19 cumreward 1.0 avg. duration                 2.46153846154 switches 13\n",
      "Run 0 episode 963 steps 8 cumreward 1.0 avg. duration                 5.0 switches 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 episode 964 steps 3 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 965 steps 7 cumreward 1.0 avg. duration                 4.0 switches 2\n",
      "Run 0 episode 966 steps 21 cumreward 1.0 avg. duration                 2.54545454545 switches 11\n",
      "Run 0 episode 967 steps 8 cumreward 1.0 avg. duration                 3.66666666667 switches 3\n",
      "Run 0 episode 968 steps 11 cumreward 1.0 avg. duration                 2.25 switches 8\n",
      "Run 0 episode 969 steps 16 cumreward 1.0 avg. duration                 2.5 switches 10\n",
      "Run 0 episode 970 steps 12 cumreward 1.0 avg. duration                 3.75 switches 4\n",
      "Run 0 episode 971 steps 13 cumreward 1.0 avg. duration                 2.3 switches 10\n",
      "Run 0 episode 972 steps 12 cumreward 1.0 avg. duration                 2.71428571429 switches 7\n",
      "Run 0 episode 973 steps 9 cumreward 1.0 avg. duration                 2.33333333333 switches 6\n",
      "Run 0 episode 974 steps 4 cumreward 1.0 avg. duration                 3.0 switches 2\n",
      "Run 0 episode 975 steps 11 cumreward 1.0 avg. duration                 3.75 switches 4\n",
      "Run 0 episode 976 steps 4 cumreward 1.0 avg. duration                 2.5 switches 2\n",
      "Run 0 episode 977 steps 4 cumreward 1.0 avg. duration                 2.0 switches 4\n",
      "Run 0 episode 978 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 979 steps 12 cumreward 1.0 avg. duration                 2.42857142857 switches 7\n",
      "Run 0 episode 980 steps 2 cumreward 1.0 avg. duration                 2.0 switches 2\n",
      "Run 0 episode 981 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 982 steps 6 cumreward 1.0 avg. duration                 1.8 switches 5\n",
      "Run 0 episode 983 steps 6 cumreward 1.0 avg. duration                 2.33333333333 switches 3\n",
      "Run 0 episode 984 steps 15 cumreward 1.0 avg. duration                 2.5 switches 8\n",
      "Run 0 episode 985 steps 5 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 986 steps 11 cumreward 1.0 avg. duration                 2.57142857143 switches 7\n",
      "Run 0 episode 987 steps 7 cumreward 1.0 avg. duration                 2.75 switches 4\n",
      "Run 0 episode 988 steps 7 cumreward 1.0 avg. duration                 2.25 switches 4\n",
      "Run 0 episode 989 steps 3 cumreward 1.0 avg. duration                 4.0 switches 1\n",
      "Run 0 episode 990 steps 7 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 991 steps 10 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 992 steps 5 cumreward 1.0 avg. duration                 2.66666666667 switches 3\n",
      "Run 0 episode 993 steps 13 cumreward 1.0 avg. duration                 2.44444444444 switches 9\n",
      "Run 0 episode 994 steps 10 cumreward 1.0 avg. duration                 3.0 switches 5\n",
      "Run 0 episode 995 steps 10 cumreward 1.0 avg. duration                 2.25 switches 8\n",
      "Run 0 episode 996 steps 8 cumreward 1.0 avg. duration                 3.0 switches 3\n",
      "Run 0 episode 997 steps 5 cumreward 1.0 avg. duration                 2.0 switches 3\n",
      "Run 0 episode 998 steps 13 cumreward 1.0 avg. duration                 3.16666666667 switches 6\n",
      "Run 0 episode 999 steps 11 cumreward 1.0 avg. duration                 4.66666666667 switches 3\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pickle\n",
    "from model import Tabular, SoftmaxPolicy, EgreedyPolicy, \\\n",
    "    SigmoidTermination, IntraOptionQLearning, IntraOptionActionQLearning, \\\n",
    "    TerminationGradient, IntraOptionGradient, ModelLearning\n",
    "\n",
    "discount = 0.99\n",
    "lr_term = 0.25\n",
    "lr_intra = 0.25\n",
    "lr_critic = 0.5\n",
    "epsilon = 0.01\n",
    "temperature = 0.10\n",
    "noptions = 4\n",
    "nsteps = 1000\n",
    "\n",
    "nruns = 1\n",
    "nepisodes = 1000\n",
    "verbose = True\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "env = gym.make('Fourrooms-v0')\n",
    "\n",
    "history = np.zeros((nruns, nepisodes, 2))\n",
    "mean_R_error = np.zeros((nruns, nepisodes, noptions))\n",
    "mean_P_error = np.zeros((nruns, nepisodes, noptions))\n",
    "max_R_error = np.zeros((nruns, nepisodes, noptions))\n",
    "max_P_error = np.zeros((nruns, nepisodes, noptions))\n",
    "\n",
    "for run in range(nruns):\n",
    "    # Run whole loop twice\n",
    "    # - compute model of options learnt the first time with dynamic programming\n",
    "    # - record absolute error of model learnt w.r.t this model as we learn the second time\n",
    "    for i in range(2):\n",
    "        features = Tabular(env.observation_space.n)\n",
    "        nfeatures, nactions = len(features), env.action_space.n\n",
    "\n",
    "        # The intra-option policies are linear-softmax functions\n",
    "        option_policies = [SoftmaxPolicy(rng, nfeatures, nactions, temperature)\n",
    "                           for _ in range(noptions)]\n",
    "\n",
    "        # The termination function are linear-sigmoid functions\n",
    "        option_terminations = [SigmoidTermination(rng, nfeatures) \n",
    "                               for _ in range(noptions)]\n",
    "\n",
    "        # E-greedy policy over options\n",
    "        policy_over_options = EgreedyPolicy(rng, nfeatures, noptions, epsilon)\n",
    "        #policy_over_options = SoftmaxPolicy(rng, nfeatures, noptions, 0.001)\n",
    "\n",
    "        # Different choices are possible for the critic. Here we learn an\n",
    "        # option-value function and use the estimator for the values upon arrival\n",
    "        critic = IntraOptionQLearning(discount, lr_critic, \n",
    "                                      option_terminations, policy_over_options.weights)\n",
    "\n",
    "        # Learn Qomega separately\n",
    "        action_weights = np.zeros((nfeatures, noptions, nactions))\n",
    "        action_critic = IntraOptionActionQLearning(discount, lr_critic, \n",
    "                                                   option_terminations, \n",
    "                                                   action_weights, critic)\n",
    "\n",
    "        # Improvement of the termination functions based on gradients\n",
    "        termination_improvement = TerminationGradient(option_terminations, \n",
    "                                                      critic, lr_term)\n",
    "\n",
    "        # Intra-option gradient improvement with critic estimator\n",
    "        intraoption_improvement = IntraOptionGradient(option_policies, \n",
    "                                                      lr_intra)\n",
    "\n",
    "        # Model learning\n",
    "        model_learning = ModelLearning(nfeatures, noptions, discount)\n",
    "\n",
    "        for episode in xrange(nepisodes):       \n",
    "            phi = features(env.reset())\n",
    "            option = policy_over_options.sample(phi)\n",
    "            # Record starting state for model learning\n",
    "            model_learning.start(phi, option)\n",
    "            action = option_policies[option].sample(phi)\n",
    "            critic.start(phi, option)\n",
    "            action_critic.start(phi, option, action)\n",
    "\n",
    "            cumreward = 0.\n",
    "            duration = 1\n",
    "            option_switches = 0\n",
    "            avgduration = 0.\n",
    "\n",
    "            for step in range(nsteps):\n",
    "                observation, reward, done, _ = env.step(action)\n",
    "                phi = features(observation)\n",
    "\n",
    "                # Termination might occur upon entering the new state\n",
    "                if option_terminations[option].sample(phi):\n",
    "                    # Model learning step when an option terminates\n",
    "                    model_learning.record(phi, cumreward + reward, duration)\n",
    "                    option = policy_over_options.sample(phi)\n",
    "                    # Record starting state for model learning\n",
    "                    model_learning.start(phi, option)\n",
    "                    option_switches += 1\n",
    "                    avgduration += (1. / option_switches) * \\\n",
    "                        (duration - avgduration)\n",
    "                    duration = 1\n",
    "\n",
    "                action = option_policies[option].sample(phi)\n",
    "\n",
    "                # Critic update\n",
    "                update_target = critic.update(phi, option, reward, done)\n",
    "                action_critic.update(phi, option, action, reward, done)\n",
    "\n",
    "                if isinstance(option_policies[option], SoftmaxPolicy):\n",
    "                    # Intra-option policy update\n",
    "                    critic_feedback = action_critic.value(phi, option, action)\n",
    "                    critic_feedback -= critic.value(phi, option)\n",
    "                    intraoption_improvement.update(phi, option, action, \n",
    "                                                   critic_feedback)\n",
    "                    # Termination update\n",
    "                    termination_improvement.update(phi, option)\n",
    "\n",
    "                cumreward += reward\n",
    "                duration += 1\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            # First run: learn model of final options by dynamic programming\n",
    "            if i == 0:\n",
    "                \n",
    "            \n",
    "            history[run, episode, 0] = step\n",
    "            history[run, episode, 1] = avgduration\n",
    "            # Record model learning absolute errors\n",
    "            R_error = np.absolute(model_learning.R - R)\n",
    "            P_error = np.absolute(model_learning.P - P)\n",
    "            mean_R_error[run, episode] = np.mean(R_error, axis=0)\n",
    "            mean_P_error[run, episode] = np.mean(P_error, axis=(0, 2)) \n",
    "            max_R_error[run, episode] = np.max(R_error, axis=0)\n",
    "            max_P_error[run, episode] = np.max(P_error, axis=(0, 2))\n",
    "\n",
    "            if verbose:\n",
    "                print('Run {} episode {} steps {} cumreward {} avg. duration \\\n",
    "                    {} switches {}'.format(run, episode, step, cumreward, \n",
    "                                           avgduration, option_switches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNX9//HXh4Q17KussojgBmJxq9a6W7UVa63L11bb\n8q3tt6td/Fa7udRvq/1ZrfZr/Za61lqttVqtUgQBF7Si4MYmEjbZAgECCYTsn98f9yRMwmQyEzKZ\nkHk/H488cu+5d2bO5Cbzzjnn3nPN3REREUlWh0xXQEREDiwKDhERSYmCQ0REUqLgEBGRlCg4REQk\nJQoOERFJiYJDRERSouAQEZGUKDhERCQluZmuQDr079/fR44cmelqiIgcUBYuXLjV3Qc0tV+7DI6R\nI0eyYMGCTFdDROSAYmZrk9lPXVUiIpISBYeIiKREwSEiIilRcIiISErSFhxm9oCZbTGzxTFlfc1s\nlpmtCN/7hHIzs7vNLN/M3jezY2Iec1XYf4WZXZWu+oqISHLS2eJ4CPhUg7LrgNnuPhaYHdYBzgXG\nhq+rgXshChrgBuB44DjghtqwERGRzEhbcLj7K8D2BsVTgIfD8sPAhTHlf/LIG0BvMxsMnAPMcvft\n7l4EzGLfMBIRkVbU2mMcg9x9U1guAAaF5aHAupj91oeyxsrT7t11O1i8YWdrvJSIyAElY4PjHt3s\nvMVueG5mV5vZAjNbUFhYuN/Pd+E9r/Hp381rgZqJiLQvrR0cm0MXFOH7llC+ARges9+wUNZY+T7c\nfZq7T3b3yQMGNHnFvIiINFNrB8ezQO2ZUVcBz8SUXxnOrjoB2Bm6tF4AzjazPmFQ/OxQJiIiGZK2\nuarM7DHgVKC/ma0nOjvqVuAJM5sKrAUuCbtPB84D8oFS4MsA7r7dzH4BvBX2u9ndGw64i4hIK0pb\ncLj75Y1sOiPOvg58s5HneQB4oAWrJiIi+0FXjouISEoUHCIikhIFh4iIpETBISIiKVFwiIhIShQc\nIiKSEgWHiIikRMEhIiIpUXCIiEhKFBwiIpISBYeIiKREwSEiIilRcIiISEoUHCIikhIFh4iIpETB\nISIiKVFwiIhIShQcIiKSEgWHiIikRMEhIiIpUXCIiEhKFBwiIpISBYeIiKREwSEiIilRcIiISEoU\nHCIikhIFh4iIpETBISIiKVFwiIhIShQcIiKSEgWHiIikJCPBYWbfM7MlZrbYzB4zsy5mNsrM5ptZ\nvpn91cw6hX07h/X8sH1kJuosIiKRVg8OMxsKfAeY7O5HAjnAZcBtwJ3ufghQBEwND5kKFIXyO8N+\nIiKSIZnqqsoFuppZLtAN2AScDjwZtj8MXBiWp4R1wvYzzMxasa4iIhKj1YPD3TcAtwMfEQXGTmAh\nsMPdq8Ju64GhYXkosC48tirs36/h85rZ1Wa2wMwWFBYWpvdNiIhksUx0VfUhakWMAoYAecCn9vd5\n3X2au09298kDBgzY36cTEZFGZKKr6kxgtbsXunsl8BRwEtA7dF0BDAM2hOUNwHCAsL0XsK11qywi\nIrUyERwfASeYWbcwVnEGsBSYC1wc9rkKeCYsPxvWCdvnuLu3Yn0BWLxhJ3fM+rC1X1ZEpM3JxBjH\nfKJB7reBRaEO04AfAd83s3yiMYz7w0PuB/qF8u8D17V2nQE+/bt53D17RSZeWkSkTcltepeW5+43\nADc0KF4FHBdn3zLg861RLxERaZquHE9RBnrJRETaFAVHipQbIpLtFBwpUm6ISLZTcIiISEoUHCnS\nGIeIZDsFR4oUGyKS7RQcKVKDQ0SynYIjRa42h4hkOQWHiIikRMGRInVViUi2U3CIiEhKmgwOMxtk\nZveb2b/C+uFmNrWpx7VXanGISLZLpsXxEPAC0U2XAD4ErklXhdo6DY6LSLZLJjj6u/sTQA3U3b61\nOq21EhGRNiuZ4NhtZv0I176Z2QlE9/3OSuqqEpFsl8z9OL5PdBe+MWb2GjCAvXfqyxpmUWgoN0Qk\n2zUZHO7+tpl9EhgHGLA83Cs8K2muKhHJdo0Gh5ld1MimQ80Md38qTXVqk4yotaHYEJFsl6jF8Znw\nfSDwcWBOWD8NeB3IquAQEZFIo8Hh7l8GMLOZwOHuvimsDyY6RTcrqadKRLJdMmdVDa8NjWAzMCJN\n9WkTEo5jKDhEJMslc1bVbDN7AXgsrF8KvJi+KmVevNywcFqVLgAUkWyXzFlV3zKzzwKnhKJp7v50\neqvVdqmrSkSyXTItDogGw6uIOmreTF912gZlg4hI45KZ5PASorC4GLgEmG9m7foCwERjHAoVEcl2\nybQ4fgIc6+5bAMxsANEYx5PprFgmxQsHq92mvioRyXLJnFXVoTY0gm1JPu6ApZOqREQal0yLY0ac\ns6qmp69KmRfvzCkLTQ41OEQk2yVzVtW1YfqRk0NRuz+rKnGLQ8khItmtyeAwszzgGXd/yszGAePM\nrGM2T3QoIpLNkhmreAXobGZDgRnAF9nPKUfMrLeZPWlmH5jZMjM70cz6mtksM1sRvvcJ+5qZ3W1m\n+Wb2vpkdsz+vnYyE3VFqcIhIlksmOMzdS4GLgHvd/fPAEfv5uncBM9x9PDARWAZcB8x297HA7LAO\ncC4wNnxdDdy7n6/dpLhjHOG8KuWGiGS7pILDzE4ErgCeD2U5zX1BM+tFdBX6/QDuXuHuO4ApwMNh\nt4eBC8PyFOBPHnkD6B0mWswIDY6LSLZLJjiuAa4Hnnb3JWY2Gpi7H685CigEHjSzd8zsvjCOMihm\nMsUCYFBYHgqsi3n8+lCWNnHDofasKrU5RCTLJXNW1cvAyzHrq4Dv7OdrHgN8293nm9ld7O2Wqn0N\nN7OUPqHN7GqirixGjNi/yXsVDSIijUt0B8Dfuvs1ZvZP4nyWuvsFzXzN9cB6d58f1p8kCo7NZjbY\n3TeFrqjaiw43AMNjHj8slDWszzRgGsDkyZP367M/4ZQjShURyXKJWhyPhO+3t+QLunuBma0zs3Hu\nvhw4A1gavq4Cbg3fnwkPeRb4lpk9DhwP7Gxwf5AWp5OqREQal+gOgAvD95fNrBMwnuhzc7m7V+zn\n634beDQ87yrgy0TjLU+Y2VRgLdGEihBdpX4ekA+Uhn3TKu79OOq2KTpEJLslcwHg+cD/ASuJPj9H\nmdnX3P1fzX1Rd38XmBxn0xlx9nXgm819rWZJdOW4ckNEslwyc1X9BjjN3fMBzGwM0Wm5zQ6Otk5n\nTomINC6Z03FLakMjWAWUpKk+bYJaFSIijUumxbHAzKYDTxB14nweeCtMfIi7P5XG+mVE3Ms4NDuu\niAiQXHB0ATYDnwzrhUBX4DNEn7HtLjgSUTeWiGS7ZC4ATPtZTG1NvDOn6uaqUm6ISJZrdIzDzJ6I\nWb6twbaZ6axUpikbREQal2hwfGzM8lkNtg1IQ13aDN06VkSkcYmCI2svoE40jqELAEUk2yUa4+hm\nZpOIwqVrWLbw1bU1Kpcx8a4ct0Y3iYhklUTBsQm4IywXxCzXrrdbCZtaSg4RyXKJ5qo6rTUr0pYo\nHEREGpfMleNZJ/G1GkoVEcluCo4k7Z0dN6PVEBHJuITBYZHhifZpj3Q6rohI4xIGR5jSfHor1aXN\niD9Xla4cFxGB5Lqq3jazY9NekzZE12qIiDQumUkOjweuMLO1wG6i7n539wlprVkGJe6qUqiISHZL\nJjjOSXstDiBqjIhItmuyq8rd1wLDgdPDcmkyjzuQJb7neKtWRUSkzWkyAMzsBuBHwPWhqCPw53RW\nKtMSzlWlrioRyXLJtBw+C1xANL6Bu28EeqSzUpkWt1WhOwCKiADJBUdFOC3XAcwsL71Vyry42aDA\nEBEBkguOJ8zsD0BvM/sq8CLwx/RWS0RE2qpkbh17u5mdBRQD44Cfu/ustNcsg+Jex6GuKhERoIng\nMLMLgUOARe5+betUKfMST3Go5BCR7JbonuO/B74H9AN+YWY/a7VaZZhOxxURaVyiFscpwER3rzaz\nbsCrwC9ap1qZpnQQEWlMosHxCnevBnD3Uvb+093uaXZcEZHGJWpxjDez98OyAWPCevufqyrRNvVV\niUiWSxQch7VaLdqYuGMctdOqt3JdRETamkT3HF/bmhVpSxJOOaLkEJEsl7HJCs0sx8zeMbPnwvoo\nM5tvZvlm9lcz6xTKO4f1/LB9ZLrrpnAQEWlcJme5/S6wLGb9NuBOdz8EKAKmhvKpQFEovzPsl0FK\nFRHJbikFh5n1MbP9HhQ3s2HA+cB9Yd2A04Enwy4PAxeG5SlhnbD9DKsdcEiT+GMcjW8TEckmyUyr\n/pKZ9TSzvsDbwB/N7I79fN3fAv8N1IT1fsAOd68K6+uBoWF5KLAOIGzfGfZPm8TTqkPR7gp2lFak\nswoiIm1WMi2OXu5eDFwE/MndjwfObO4LmtmngS3uvrC5z9HI815tZgvMbEFhYeF+PVdTV45P+sUs\njr65XU/XJSLSqGSCI9fMBgOXAM+1wGueBFxgZmuAx4m6qO4imn239iyvYcCGsLyB6A6EhO29gG0N\nn9Tdp7n7ZHefPGDAgBaopoiIxJNMcNwMvACsdPe3zGw0sKK5L+ju17v7MHcfCVwGzHH3K4C5wMVh\nt6uAZ8Lys2GdsH2Op/kqvIRXjmuQQ0SyXDLTqv8N+FvM+irgc2moy4+Ax83sFuAd4P5Qfj/wiJnl\nA9uJwiatmhrjEBHJZk0GR2hh3AWcQPS5+W/geyFA9ou7vwS8FJZXAcfF2acM+Pz+vlZq9dq3rO7K\ncSWHiGS5ZLqq/gI8AQwGhhC1Ph5LZ6UybWXhrka36X4cIpLtkgmObu7+iLtXha8/A13SXbFM+v4T\n72W6CiIibVaTXVXAv8zsOqIzoBy4FJgeruvA3bensX5tjxocIpLlkgmOS8L3rzUov4zoY3R0i9ao\njaq7jiOjtRARybxkzqoa1RoVaSvmLt+ScLsGx0Uk2yUz5Ug3M/upmU0L62PD1d/t0pcffCtued1c\nVWpziEiWS2Zw/EGgAvh4WN8A3JK2GrVxanGISLZLJjjGuPuvgUrIvvuPi4hIfckER4WZdSWMC5vZ\nGKA8rbVqw9TgEJFsl8xZVTcCM4DhZvYo0SSFX05npdqm2ivHFR0ikt2SOatqppktJJpyxIDvuvvW\ntNesjVJsiEi2S+asqtnuvs3dn3f359x9q5nNbo3KtSWmCzlERIAELQ4z6wJ0A/qbWR/2Doj3ZO/d\n+UREJMsk6qr6GnAN0cSGC9kbHMXA/6a5Xm2WruMQkWzXaFeVu98Vrhr/obuPdvdR4Wuiu2dvcMTk\nxtSH4l8sKCLSnjUaHGZ2rJkd5O6/C+tXmtkzZnZ37QSH2aS2uVUTExyzP0g8PYmISHuUaHD8D0RX\njGNmpwC3An8CdgLT0l+1tqVrpxwA9lRWZ7gmIiKZlWiMIydmyvRLgWnu/nfg72b2bvqr1rbkdYp+\nVLvLqzJcExGRzErU4sgxs9pgOQOYE7MtmQsH25W8zlGLQ8EhItkuUQA8BrxsZluBPcCrAGZ2CFF3\nVVbpFlocuxQcIpLlGg0Od/+fcKHfYGCm751rowPw7daoXFvSIYyOq8UhItkuYZeTu78Rp+zD9FWn\n7apNzV3lGhwXkeyWzOy4EqOmJrkLAGtqnHfX7UhzbUREWp+CI0m1HXU1Sc6Oe9+8VVx4z2v8e+W2\nNNZKRKT1KThSlOyEI8sLdgGwvqg0fZUREckABUeSagMj2RZH7WB6svuLiBwoFBypSjIHckJyVNek\nsS4iIhmg4EhS7dnISbc4QnCoxSEi7Y2CI0XJxkBtV5VuNSsi7Y2CI0VJno1LB6vtqlJwiEj7ouBI\nQtHuCl5dEd1mPdkWRF1wKDdEpJ1p9eAws+FmNtfMlprZEjP7bijva2azzGxF+N4nlFu4B0i+mb1v\nZse0dp1XFu6qW06256l2cDzZCwZFRA4UmWhxVAE/cPfDgROAb5rZ4cB1wGx3HwvMDusA5wJjw9fV\nwL2tX+W9kr11bI4Gx0WknWr14HD3Te7+dlguAZYBQ4EpwMNht4eBC8PyFOBPHnkD6G1mg1u52nVq\nkjy9tvbCPzU4RKS9yegYh5mNBCYB84FB7r4pbCoABoXlocC6mIetD2UNn+tqM1tgZgsKCwtbtJ5e\nb7npJHhrzXamLyoA1OIQkfYnY8FhZt2BvwPXuHtx7LYwhXtKn7juPs3dJ7v75AEDBrRgTeuPayTT\ngthVtnfqdZ1VJSLtTUaCw8w6EoXGo+7+VCjeXNsFFb5vCeUbgOExDx8WyjIimQZEl445dctqcYhI\ne5OJs6oMuB9Y5u53xGx6FrgqLF8FPBNTfmU4u+oEYGdMl1ari3c67paSMuZ+sCXuPjqrSkTam0zc\nO/wk4IvAIjN7N5T9GLgVeMLMpgJrgUvCtunAeUA+UAp8uXWrW1+8GLhs2husKtzNql+eR4cORnVM\ncFSrxSEi7UyrB4e7zwOskc1nxNnfgW+mtVIpiNf1tKpwNxA7g+7ebZrkUETaG105nqJEDYjagfDY\ncNFcVSLS3ig4UpRosLt2W2xY6KwqEWlvFBxJSLbVUHd72ZjuKcWGiLQ3Co4UJdPiqK7XVZX2KomI\ntCoFRxLqXTmeaIwjTldVsnNbiYgcKBQcKUrU4vCa2n1iypQbItLOKDiS4AmCYP6qbXXLtaHS8Kyq\ns+54mVueW5rWOoqItBYFR4zGBsFju5sa7nLptDfqluvGOBqcSbViyy7um7e6hWopIpJZCo4YlY3c\nrq9eiyPBmMXHbnkxzv4iIu2LgiNGWVV13PLYrqdkLsuov7+iQ0TaFwVHjLLKxoJj73Iy13RocFxE\n2jMFR4zyyvgTS+1Pi0O5ISLtjYIjRmMtDm9wllRTYqdS11xVItLeKDhilMVpcbh7vRluk4mB+rPj\ntmxwPPveRkZe9zzbdpW36POKiCRLwRGje5f4s8ynOtgdu09LT6v+8OtrAFi9dXfLPrGISJIUHDFG\n9c/jP44fUa/MvWFXVeLncPeku7bWbS+lKsVkUdeXiGSagiMJsb1NTfU8Vdd4ve6pxu4AuLm4jE/8\nei63/uuDlqiiiEirUXAkoV5XVRPJUe1eL1yqYlZ2lVdx+m9e4r11O9gaxijm5W9tVp2ssXsoioik\nmYKjCU7DFkfi4Kipqb9PZdXerqiFa4tYVbib22cub+lqioi0GgVHEurd0a+J4Kh2rzcOUhkzhhFv\nfMLUdBCRA4yCownu3mC228T7V1fX37+qka4tjXGLyIFKwdFAvP//Y28F29RpsNXu9VolFVX7njX1\n6oqtzQ6O2ofpVuYikikKjia8v2EnP/jbe0nvX13TeFdVbLdUZUij5nZUVTUyk6+ISLopOBpo+HH8\n2xdXpPT4Gvd6Z141NlV7aXk0vUm8IY49FfGnPonV0leki4gkS8HRhPJG5q9qTHVN/dNxY7u2YgfH\ni8sq65Xf9M8lLNtUzL8WbeKwn89g2abihK9TVdPCl6SLiCRJwdGEdz7akdL+j7/5EU8sWFe3vqu8\nqm45tpXwjUffBqIWx+bich58bQ3/+fACpi8uAODDzSUJX2f+6u0UlpSzsnBX3O1LNxYz54PNKdVd\nRCQZCo4GGvYcVaQ4Jcjdc/LZsGNP3G3xuq0WbyhmzbaoVVJSVslbq7cDoeWSoDvq3pdWcvJtczjj\nNy/XlU2+5cW6uazOu/tVvvLQgriP3Vxcxvf++m5SXWIiIg0pOFpRY91LP3l6EQDFZVUUFJcB8P0n\n3uPel1cmfL7ymDO2yquq2bqrnBueXcI1j7+T8HG/nL6Mp9/ZwAtLCurKCnaW8ej8tXXrq7fuZn1R\nKUW7K+I+x/bdFSzZuDPh6zTXzj2VGsMRacMUHK3ow83xu5W2FMefIv2h0HqIHlvC+qLSuPu5O7vL\n97Ye/vHuxrrleK2WeJ/J33h0IT95ejGbdkatpdNuf4mTb5vLpF/M4gv3zaeyuoZ7X1pZ10qZcs88\nzr97Xtz61NapsCR6X+VV1ZTEjOkkUlldw8SbZnLjs0uS2v+Rf69hYyMtPIDXV26Ne0p0rD0V1Yy8\n7nkeeWNtwv1EWlpldQ2vNXPaoUxScDRw5Ykj6d45l4N6dmnx556+aFPc8pKYcZBYhSXlrAhjHWff\n+Qon3zY37n5llTXsbuQ5dldUsaWkjEXro9ZBRVVNXSvCDO6evYKP/2o2W3dV1L1mwyvc5+Vv5el3\nNnDbjA847Ocz+O7j77Bue/RhHdsyKKus5oUlBZRWVDFz6WaO/Z8XeXVFISffNpcL73mt3nMu3VjM\nuXe9Sv6WKExXFu5i9dbddXN4/W3hOhLZWVrJovU7+dkzS5hyz2vsLK1k55764fTw62v4jz/O55fT\nlyV8ro0hLH/2j8X1buY1a+nmFpuE8sPNJXz7sXeaDLFE/jL/I95bF3/Mrayyut77X19UygcFxfz+\npXwKS8q579VVnH/3qwnHzpZuLKZgZ1nd+u7yKu6Zm7/PDM7LC0pYt72U0ooqxvx4Os+8u6Fu27Zd\n5XFbi1t3lac8E3Q881Zs5ZUPC/frOcqrqnm9hT6sd5VXMXNJQb2xzHi++Ze3+cajC/cpv+vFFVxx\n33xmLN4Ud2YJd2faKys5+uaZbWpC1Pg3oGiDzOxTwF1ADnCfu9+ajtcZd1APFt90Dufc+Updt1FL\nac6HxpwPtnBwv7y69Xh/lOuKSpn68FtxH79wbRFfejDadtExQ3nq7b1/5Jt2lnHHrA8B6oLy3XU7\nmPPBln2ep7b1APBMTItmV1kVvbp1pLK6hpNvm1v3wZ/TIRoteuTfayksKaewpJzfzV5BXudcPjtp\naN1ZZGfe8TJrbj2/bqymZ7gnSlllDTU1TmVNDfNXbaeotILBvbpy3Ki+FO2uYNIvZtWr28SbZwLw\nq4uOYkTfbpSUVXFDaLU89PoaJo3ozZKNxVz3qfF06GA8MG81Rw3rxej+eawu3Hvm2/ifzdjnvZ98\nSH9OHNOPp95ez5DeXRkzoDt98joyY3EBHxSU0CU3h+fe38h1547njMMG4e77TCXztUcWsnrrbv75\n3kZ6dMll0Y3n1G3bU1HNG6u3cdq4gQDM/WAL/bt35qBeXeiX14mXPyzk+NF9+XHo0nzl2tPYUlLG\n5JF9657j8j++wTsf7WDNredTFY5FrV/P2Ds32tl3vsJ/nTqGvE45HDeqH2bwsRF92FJSznl3vwrA\n8985GcN48LXV/G3hep5+ZwM/+/ThbC0pZ+223dw9Jx+A2T/4JNU1zs3/XMpnJgxhS0k5J/xqNhce\nPYTe3ToxaURvFm/YyUOvr6Gy2jl+VF/++rUT6+pyz9x8/vjqKt79+dl88f75HDKwOzd85gggCrEe\nXXIZ3rcbC9cWsWxTMV844WC+cP98AP545WRmLC5gwrBenHRIP3I6dOBrjyzgts9NYHNxOc++t4EZ\niwu489KjuWDiEO6ft5qzDh/Ewf3yuOW5ZTzyxlpunnIEV544kl3lVby9tohTDh3A9t0V5HXO4fdz\nVzKibzdOOqQ/HSz6u5iXv5VTxw3gtHED647vkTe8AMDoAXmMG9SD08cPZEjvruR2MG54dgkXHTOU\nr35iNM+/H/3TuHHHHs6961WuPWccr64orDvr8ut/fpuvfXI0V39iNC8tL2Ti8F6MGdCdN1dv55fT\no8D4v5dX8t66HTwy9TiKy6r4aHsp989bzR2XTGTTjjKKyyrZXFzGiWP60a1Tej/a7UC4v4OZ5QAf\nAmcB64G3gMvdfWm8/SdPnuwLFsQfGE7WKb+ey0fb43cNtbbvnDGWu2dH15MM6dWFjTtbNtD21wmj\n+/LGqu1J7985twNjBnRnaROnHB/crxvdO+eyZGO0X8cc47RxA5m5tPlniw3q2ZnNjXQNtqTrzh3P\n0N5d6d4ll3vm5LNgbVG97YcN7smyTcX06daRotKopdClYwcmDOvNm6v3/Vl+Ymx/Xl1R/7/kcYN6\nsHxzCZMP7rPP86diRN9urfa7/tp1p3P3iys4f8JgrnzgzX22nz9hcN2HbEv5xqlj+P1LK+mc24Er\njj+YB15bXbftyKE9Wbyh/u/hUUN7sWhD0+N3l0wexhML1je53/+7eALXPvl+yvW+6YIj6v75ScXE\nYb145lsnp/w4ADNb6O6Tm9zvAAmOE4Eb3f2csH49gLv/Kt7+LREcx/7PixSWlHPTBUdQWFLO/87N\nr7e9X14ntjUycAzRQT95bP96Zz21B6ccOoAVm0vY1MbCS0Qit33uKC49dkTTO8aRbHAcKGMcQ4HY\nTu/1oSxtvvTxkQBcdtxwfnjOON76yZn8YsoRjBvUA4AhvbvyyrWnccjA7vTq2pGuHXPqPb5751zG\nDOjO6l+dF/f5PzNxCH/44sc4uF+3fbadPn4gr193Ok9+/cQ4j4xcftwIrjlzbL2ysw4fxMThvRk7\nsHtS73FIr/jjOBOG9eLeK47h/KMG1yufcvQQ/vSV45hxzSlxHzesT9e65QuPHsJlxw4HYPLBfert\n95WTRgHQu1tHFv70TM48bBA9OqfWtP7r1SfULd885Yh9to8/qAevXHsa//eFY5J6vvOOOog+3TrW\nqx/ALRceSd+8TgB8/6xDWfjTMzljfNSldPvnJ/LVT4xizg8+yQNf2vu3NuXoIY2+zmnjBtApZ++f\n3eBwDPp371xvv/86dUxS9W7McaP61lu/67Kj6dYph8kH9+HqU0YD8MCXJjP15Oi9Hj64Z92+V514\n8D7P98jU47j98xN59+dncdMF+/68e4ef3Wcn7f2z7NU1Krv/qsnc9rmjGq3ruEE9+PmnD290+yfG\n9q9b/viYfo3uF89RQ3sl3N6jcy7fOu0QbvjM4Zw4uv5zX3TMUH5w1qH1yo4b2Zf3bzybE0bX//k2\n5YdnH9rottrf/dq/n9pu49rfx1qLbzqHR6YeV69s/EE96pZ/ffEEvnHqGC6ZPDylujXHgdLiuBj4\nlLv/Z1j/InC8u38rZp+rgasBRowY8bG1a9Nzhoy787s5+Xx20lCG9+1WV1bb51leVc2MxQWcc8RB\ndAlhUlpRRfGeKg4KHxI1NY7Z3rmrNuzYQ99unejaKYeVhbsYM2DvB3/+lhJeX7mNicN688qHhawv\n2sNXTh6TvOPyAAAJ50lEQVTF6AF5dMzpwAtLCsjtYIzo242xg3rEVpV5K7bywpICDh3UnUuOHc6m\nHWVs3LmH/C27OPXQgYwIobWqcBd5nXNZX7SHPRXVTBrRm7yYD/KZSwp4Y9V2fnTuODrn7g3IF5du\nJqeDUV5VzYRhveneJZfKqhreX7+T08YPZEdpBa+v3Ma5Rx5E8Z4qyqurGdC9M+VVNUxftIkpRw+t\nGwsBmL9qGz27dmTaK6sYf1APRvbPo2OO8Zf567jxgsPZuquCmUsK+MzEIRw2uCdlldXMXraF8ydE\nATfng82s3lrKwX27cebhg+r9HPK3lNCrW0e6dszlnCMGsXBtEaP651FaUU2fvE50D+93ZeEuRvbL\n445Zy/nCCQczuFdXKqpqWFdUWu+4xLN9dwVV1TUM7NmFddtL+eHf3uPcIw/isuNG0Dm3Q93xdnfe\nW7+TDgYThvWuGxRdWbiLUf270yH8bmzauYftuysYM6A7ywtKKCwp56012/niiQfTvXMuPbt05Dez\nlnP+UUPo2imH99btYGXhLs6fMJhxg3pgZlTXOKsKd3HIwO6YWd3vauzv7IYdexjUozObwxjGx8f0\nZ0tJGVXVzoYde5i9bAvXnjOu3rHK31LCkN5dmbV0M5OG96F3Xkf2VFQzqGcXFqzZzrKCEi4/djgF\nxWUM6xP9nhXsLKNzbgeWbiqmqLSCM8YP4qPtpRw6KKpb/pYSRvfvzl2zV3DooB4s21TMV08ZTZeO\nHfjNzA/5r0+OoU9eJ8oqo1PPu3fOpbLaqaqpoVvHXDbu3ENep1xyc4ye4Z+5nA5W9/NdtqmEQwZ2\np1Nuh7qf9+j+efXGo2pqnFueX8bzizbyz2+dzMCeXXB3yqtqeGLBOk4fP5Bhfbrh7ixYW8TyghKm\nHD2Ex99cx9hB3Tl+VD+6dsph3fZSBvTozL9XbWNUvzxG9s+jusbJ6WC8/GEhRbsr6NW1I+MO6sGQ\n3l1xd1Zt3c1f31rHt08/hKLdlYzo140ZizcxoEcXJg3vTYeYn39xWSWl5dUc1KvLPp8n+0NdVfvZ\nVSUikm3aW1fVW8BYMxtlZp2Ay4BnM1wnEZGsdECcjuvuVWb2LeAFotNxH3D31E83EBGR/XZABAeA\nu08Hpme6HiIi2e5A6aoSEZE2QsEhIiIpUXCIiEhKFBwiIpISBYeIiKTkgLgAMFVmVgjsz6Xj/YED\nb5L85su29wt6z9lC7zk1B7v7gKZ2apfBsb/MbEEyV0+2F9n2fkHvOVvoPaeHuqpERCQlCg4REUmJ\ngiO+aZmuQCvLtvcLes/ZQu85DTTGISIiKVGLQ0REUqLgiGFmnzKz5WaWb2bXZbo+LcXMhpvZXDNb\namZLzOy7obyvmc0ysxXhe59QbmZ2d/g5vG9myd1Gr40xsxwze8fMngvro8xsfnhffw1T9GNmncN6\nftg+MpP13h9m1tvMnjSzD8xsmZmdmAXH+Xvh93qxmT1mZl3a27E2swfMbIuZLY4pS/m4mtlVYf8V\nZnZVc+uj4AjMLAe4BzgXOBy43Mwav5/lgaUK+IG7Hw6cAHwzvLfrgNnuPhaYHdYh+hmMDV9XA/e2\nfpVbxHeBZTHrtwF3uvshQBEwNZRPBYpC+Z1hvwPVXcAMdx8PTCR6/+32OJvZUOA7wGR3P5LotguX\n0f6O9UPApxqUpXRczawvcANwPHAccENt2KTM3fUVjfOcCLwQs349cH2m65Wm9/oMcBawHBgcygYD\ny8PyH4DLY/av2+9A+QKGhT+m04HnACO6KCq34fEmus/LiWE5N+xnmX4PzXjPvYDVDevezo/zUGAd\n0Dccu+eAc9rjsQZGAoube1yBy4E/xJTX2y+VL7U49qr9Bay1PpS1K6FpPgmYDwxy901hUwFQe6Pu\n9vCz+C3w30BNWO8H7HD3qrAe+57q3m/YvjPsf6AZBRQCD4YuuvvMLI92fJzdfQNwO/ARsIno2C2k\n/R9rSP24ttjxVnBkETPrDvwduMbdi2O3efQvSLs4xc7MPg1scfeFma5LK8sFjgHudfdJwG72dl8A\n7es4A4SulilEoTkEyGPfLp12r7WPq4Jjrw3A8Jj1YaGsXTCzjkSh8ai7PxWKN5vZ4LB9MLAllB/o\nP4uTgAvMbA3wOFF31V1AbzOrvetl7Huqe79hey9gW2tWuIWsB9a7+/yw/iRRkLTX4wxwJrDa3Qvd\nvRJ4iuj4t/djDakf1xY73gqOvd4CxoazMToRDbA9m+E6tQgzM+B+YJm73xGz6Vmg9syKq4jGPmrL\nrwxnZ5wA7IxpErd57n69uw9z95FEx3GOu18BzAUuDrs1fL+1P4eLw/4H3H/l7l4ArDOzcaHoDGAp\n7fQ4Bx8BJ5hZt/B7Xvue2/WxDlI9ri8AZ5tZn9BSOzuUpS7TAz5t6Qs4D/gQWAn8JNP1acH3dTJR\nM/Z94N3wdR5R3+5sYAXwItA37G9EZ5itBBYRnbGS8ffRzPd+KvBcWB4NvAnkA38DOofyLmE9P2wf\nnel678f7PRpYEI71P4A+7f04AzcBHwCLgUeAzu3tWAOPEY3hVBK1LKc257gCXwnvPR/4cnProyvH\nRUQkJeqqEhGRlCg4REQkJQoOERFJiYJDRERSouAQEZGUKDhEEjCzajN7N+Yr4azJZvZ1M7uyBV53\njZn139/nEUkHnY4rkoCZ7XL37hl43TVE599vbe3XFmmKWhwizRBaBL82s0Vm9qaZHRLKbzSzH4bl\n71h0D5T3zezxUNbXzP4Ryt4wswmhvJ+ZzQz3lbiP6CKu2tf6QniNd83sDxbdZyTHzB4K96BYZGbf\ny8CPQbKUgkMksa4Nuqoujdm2092PAv6XaDbehq4DJrn7BODroewm4J1Q9mPgT6H8BmCeux8BPA2M\nADCzw4BLgZPc/WigGriC6Arxoe5+ZKjDgy34nkUSym16F5Gstid8YMfzWMz3O+Nsfx941Mz+QTT9\nB0TTv3wOwN3nhJZGT+AU4KJQ/ryZFYX9zwA+BrwVTcVEV6LJ7P4JjDaz3wHPAzOb/xZFUqMWh0jz\neSPLtc4nmjPoGKIP/ub8o2bAw+5+dPga5+43unsR0R3+XiJqzdzXjOcWaRYFh0jzXRrz/d+xG8ys\nAzDc3ecCPyKavrs78CpRVxNmdiqw1aN7o7wC/EcoP5dockKIJrG72MwGhm19zezgcMZVB3f/O/BT\nonASaRXqqhJJrKuZvRuzPsPda0/J7WNm7wPlRLfljJUD/NnMehG1Gu529x1mdiPwQHhcKXunxb4J\neMzMlgCvE00XjrsvNbOfAjNDGFUC3wT2EN3pr/afv+tb7i2LJKbTcUWaQafLSjZTV5WIiKRELQ4R\nEUmJWhwiIpISBYeIiKREwSEiIilRcIiISEoUHCIikhIFh4iIpOT/A2H1LjyUBAwQAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10844b6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(xrange(nepisodes), np.mean(history[:, :, 0], axis=0))\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Steps Per Episode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD8CAYAAAA/iMxLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGTlJREFUeJzt3X2wXPV93/H3x+JBQTxHRoMBGzpW3coENLXAuAYH7Axg\nDx6ok/Dg2FVqpho3Ia6ZQE3SOhBaJ8zUUwc6jvFtTCVPAhh7oiJczINpQWBDQMJYQAJGEDEgY2QF\nQgCXp6tP/9ij+Opy7969e86es7vn89Ls7O552PPdq6+++t3f+Z3fkW0iIqI+b2k6gIiItknhjYio\nWQpvRETNUngjImqWwhsRUbMU3oiImqXwRkRMIekSSRcM8hgpvBERNdut6QAiIqoi6fPAJ4CfAk8B\nG4HvAlcCewGPA5+y/bykfwusAvYANgOftP2zOuKstfDuoT29kEV1HjJm8SLPb7f91qbj6EfyaHiU\nzaNTTlrkv3tusqdtN2569WHglSmLJmxP7Hwj6RjgV4Gjgd2B++kU3q8Dv2P7DkmXAhcDnwX+0vb/\nKPb9L8C5wH/v97vMR6nCK+lU4HJgAfBnti/rtv1CFvFefajMIaMi3/W3nmw6hp2SR6OrbB793XOT\n3Hvz23vadsHBj71ie0WXTd4PXG/7FeAVSTcAi4D9bd9RbLMG+Gbx+sii4O4P7A3c3M936EfffbyS\nFgBfBj4MLAPOkbSsqsCiHZJH7WZgR49/BmA1cJ7tXwL+EFg4iIPMpMzJtWOBzbafsP0acC1wejVh\nRYskj1rMmNc92dOjB98DPippoaS9gdOAl4HnJZ1QbPNJYGfrdx/gGUm7A79R8VfrqkxXwyF0Oq93\nehp47/SNJK2i04HNQvYqcbgYU8mjlquqNWv7PknrgE3As8CDwAvASuBKSXsBTwD/ptjl88Bf0TkR\n91d0CnEtBn5yrej8ngDYVwdmDsroS/JoPBkzWe3UtF+0fUlRZNcDG20/ABz3pmPbXwG+MsPyS6oM\naCZlCu9W4LAp7w8tlkXMR/Ko5XZQaeGdKM4RLATW2L6/yg+vSpnCex+wVNIRdP6hnA18vJKook2S\nRy1mYLLCwmt7JHKn78Jr+w1J59EZgrEAuMr2w6WiOe6oUrv3a/NZ3fsM33n+PbOvLBlzt2O/9V3b\nu+6736Vd4r5nU78h1Wqc8mhO3f5ORjHmilTc4h0Jpfp4bd8I3FhRLNFSyaP2MvB6C28/lkuGI6Ix\nxpV2NYyKFN6IaI5hsn11N4U3IprTuXKtfVJ4I6JBYhI1HUTtUngjojGdk2spvEPrtK/dMfdGffqT\nWz7c975zDkX7Rv/Te3YdLhYxBjrjeFN4IyJqtSMt3oiI+qTFGxFRMyMmW3jrxxTeiGhUuhoiImpk\nxGte0HQYtUvhjYjGdC6gSFdDREStcnJtiH373F/uur7MON/Pnvyd7ht0naSw+75/wuDGCHebNnK/\nj/R92BiUYZ36sUG2mHRavBERtdqRFm9ERH06J9faV4ba940jYmjk5FpERAMmM443IqI+uXItIqIB\nOzKqoVllhoStvnxw46cWT9w967rNXzpuYMeNMTOKdxkesM4kOSm8ERG1MeL1XDIcEVEfm1ZeQNG+\nbxwRQ0Ts6PEx70+WbpS0/xzb3C5pxQzLl0saWP9lWrwR0RgzmBavJAGn2e73JsbLgRXAjdVF9XNp\n8UZEoyZ5S0+PuUg6XNKjkr4OPARMSlpcrPt8se4uSddIumDKrr8u6V5JP5J0gqQ9gEuBsyQ9IOms\nqr9zWrwR0RijqidCXwqstH2PpC0Ako4BfhU4GtgduB/YOGWf3WwfW3QtXGz7VyT9AbDC9nlVBveP\nBxzEh0ZE9KJze/eey9BiSRumvJ+wPTFtmydt3zNt2fuB622/Arwi6YZp6/+yeN4IHN5rMGUMVeGd\na+rHbhbz8qzrth+1qPu+m2bft6y5ppwsc2v53P49Rp/mMx/vdttvOhE2TT//mF8tniepqSaW6uOV\ntEXSg0U/yIa594h4s+RRe5nOlWu9PEr4HvBRSQsl7Q2c1sM+LwL7lDloN1VU95Nszz4jd0Rvkkct\nNeg7UNi+T9I6YBPwLPAg8MIcu/1f4CJJDwB/bPsbVcY0VF0NEdEutiqbq8H2FuDIKe8Pn7L6i7Yv\nkbQXsJ7i5JrtE6dsv52ij9f2c8AxlQQ2g7KF18Atkgx8dYaObiStAlYBLCR9kjGj5FFLdU6u1XLJ\n8ISkZcBCYI3t++s46GzKFt7jbW+VdBBwq6RHbK+fukHxj2gCYF8d6JLHi/GUPGqteu65ZvvjAz/I\nPJT6xra3Fs/bgLXAsVUEFe2SPGqvzsk19fQYJ30XXkmLJO2z8zVwMp2rRSJ6ljyKqq5cGyVluhqW\nAGs7l0SzG3C17ZtKRdNlvtK55r195/nTx0z/3OLZV5U2563hS+h2+3aAF/5g9nUjdHv3WvNoznlv\nu+0blRvAlWsjoe/Ca/sJOpfgRfQteRS52WVERI1seH1HCm9ERG06XQ0pvBERtRr0lWvDKIU3Ihqz\nczhZ26TwRkSD0tXQvC5DfeacXvFLs0+vWHZqxm5D1b797gO67juXx3985azrTnnb8lKf3VplbpU+\nyNusdxuqVnIY280/fmDWdcOeR/3cT23UDVfhjYhW6YxqyO3dIyJqkwsoIiIakK6GiIgaZVRDREQD\nMqohIqJGtngjhTciol7pahhic936/bNfm32sbplbqM/ltIefL7X/ey75d7Ou2/3Gn/b9uft9ZHPf\n+0YDSo4fPuVjXfbvPqNqdwOeJjN9vBERDUjhjYioUcbxRkQ0ION4IyJqZMMbmQg9IqJe6WqIiKhR\n+ngjIhrgFN7hddrX7uh733d+42dd128+a6++P3suqy8f3H3W97t0cHFH1KWNJ9fa16sdEUPD7vTx\n9vKYi6SXetjmM5L+RtJfSDpR0r+s5IvM08i0eCNiHInJekc1/BbwK7aflnQJ8BLw/ToDgLR4I6Jh\ntnp6zIekCyXdJ2mTpD8sll0J/BPgO5LOBz4NnC/pAUknVP7FukiLNyIaM8+5GhZL2jDl/YTtiekb\nSToZWAocCwhYJ+kDtj8t6VTgJNvbJe0HvGT7i+W+xfyl8EZEc9zp5+3Rdtsretju5OLxg+L93nQK\n8fp5xzcgKbwR0agBjGoQ8Me2v1r1B1elFYW3zFA0AB6uJo75ynCxMTPIW8ePKA/m5NrNwH+W9Be2\nX5J0CPC67W3TtnsR2Lfqg/dizm8s6SpJ2yQ9NGXZgZJulfRY8XzAYMOMUZc8itnYvT16/zzfAlwN\n3C3pQeBbwD4zbHoD8K+aOLnWy381q4FTpy27CLjN9lLgtuJ9RDerSR7FDKoa1WB77ymvL7f9S8Xj\nfbYfL5Yfbnt78fpHto+yvdz2nQP7gjOYs/DaXg88N23x6cCa4vUa4IyK44oxkzyKmXRas9UPJxt2\n/fbxLrH9TPH6J8CS2TaUtApYBbCQ9FnGLpJH0cpJckr3ats2neF4s62fsL3C9ord2bPs4WJMJY/a\nq+o+3lHQb+F9VtLBAMXz9LOFEb1IHrWcETt2vKWnxzjp99usA1YWr1cC11cTTrRM8ihwj49xMmcf\nr6RrgBPpXK73NHAxcBlwnaRzgSeBMwcZJMx9e/cyY3Xnmrpx8cTds67bvup9fR8XYPGml0vtPyqG\nJY8a1e1W6W0d4+vMxzsj2+fMsupDFccSYyx5FLMat+ZsD1px5VpEDK+0eCMiamRgx44U3oiI+hhI\nizciol7jNka3Fym8EdGsFN6GdRtuM4dvv7v/ia0WM/twsTn37TLULBpSIo8aM4oxV2L85mHoxXAV\n3ohon7R4IyJqZHBGNURE1C2FNyKiXulqiIioWQpvRESNcgFFRET9cgHFgL3I89u/6289OWXRYmB7\nnTH0qA1xvaOiz6ld8qi04cqjjGoYLNtvnfpe0gbbK+qMoReJa7glj8oZtriUFm9ERI3G8fYSPUjh\njYgGKSfXGjDR8PFnk7hGy7D+XBJXL9LirZft4UqAQuIaLcP6c0lcPdrRdAD1a7rFGxFtlnG8ERH1\nG9SoBkmXAC/Z/uJgjtC/tzRxUEmnSnpU0mZJFzURw0wkbZH0oKQHJG1oMI6rJG2T9NCUZQdKulXS\nY8Vz/xMQj4nkUU+xDH8uucfHGKm98EpaAHwZ+DCwDDhH0rK64+jiJNvLGx7nuBo4ddqyi4DbbC8F\nbivet1byqGeraVEuSfqPkn4k6S7gXcWy5ZLukbRJ0lpJB0g6SNLGYv3Rkizp7cX7xyXtJWm1pCsk\nfV/SE5J+rao4m2jxHgtstv2E7deAa4HTG4hjaNleDzw3bfHpwJri9RrgjFqDGj7Jox6MQi7JvT2A\nxZI2THms2uVzpPcAZwPLgY8AxxSrvg58zvZRwIPAxba3AQsl7QucAGwATpD0DmCb7Z8V+x4MHA+c\nBlxW1Xduoo/3EOCpKe+fBt7bQBwzMXCLJANfHbKzv0tsP1O8/gmwpMlghkDyqH/Dk0tmPpcMb5/j\nN4gTgLU7i6akdcAiYH/bdxTbrAG+Wbz+PvB+4APAH9H5zUDAnVM+83/Z3gH8taTKfk45ubar421v\nlXQQcKukR4oWw1Cx7eIfdQynkcgjGJJcau7o6+kU63cA1wOfK6L531O2eXXK68qGXzTR1bAVOGzK\n+0OLZY2zvbV43gaspfPr7LB4VtLBAMXztobjaVryqH9DlUvz6GqYy3rgDEm/IGkf4KPAy8Dzkk4o\ntvkksLP1eyfwCeCxolX7HJ0uirsq/HozaqLw3gcslXSEpD3o9MmsayCOXUhaVPxlIWkRcDLwUPe9\narUOWFm8Xknnf+g2Sx71b7hyqaJRDbbvB74B/BD4Dp0cgc53/K+SNtHp/7202H4LnVbszt9G7gL+\n3vbz5b9Ud7V3Ndh+Q9J5wM3AAuAq2w/XHccMlgBrJUHn53K17ZuaCETSNcCJdE4mPA1cTKdj/zpJ\n5wJPAmc2EduwSB71ZiRyqcKuBttfAL4ww6rjZtn+sCmv/4hOX+/O9785bdu9q4kS5DbOQhwRQ2Hh\noYf50H9/fk/bPv4ffnfjEAzPq0ROrkVEszIRekREvdo4PieFNyKalcI7WHtoTy9kUZ2HjFm8yPPb\np99CZ1Qkj4ZH6TzqfajYWClVeCWdClxO56zyn9nuekndQhbxXn2ozCGjItNuFtmo5NHoqiSPWlh4\n+x7HOwKTlMQISB6FdvT2GCdlLqDIJCVRheRRtE6ZwjvTJCWHTN9I0qqdswm9vstlzxFA8igyH2/1\nbE/YXmF7xe7sOejDxZhKHo2pHudpGLcTcGVOrg3tJCUxUpJHbTdmRbUXZVq8QzlJSYyc5FHbtbCr\noe8W70AmKTnuqFK7D8w9m2ZfN4oxD5HkUWEUY66AGL8RC70oNY7X9o3AjRXFEi2VPGqxMey/7UUu\nGY6IZqXwRkTULIU3IqJe6WqIiKhbCm9ERI2cUQ0REfVLizciol7p442IqFsKb0REjcbwcuBepPBG\nRGNEuhoiImqXwhsRUbcU3oiImqXwxoyGdcq+GC3JozfL7GQREQ1I4Y2IqFdVlwxLOhz4tu0ji/cX\nAHsDJwI/BH6ZTs37lO17qzlqf1J4I6JR8+hqWCxpw5T3E7Ynetx3L9vLJX0AuAo4ch4hVi6FNyKa\nM78LKLbbXtHnka4BsL1e0r6S9rf9931+VmkpvBHRrOr6eN9g1xv4LuxylEZ7lsvcZTgiopSdV671\n8ujBs8BBkn5R0p7AaVPWnQUg6XjgBdsvVP1d5iMt3l6M4t1hY/gkj2akHdU0Pm2/LulS4F5gK/DI\nlNWvSPoBsDvwqUoOWEIKb0Q0p+JJcmxfAVwxdZmk24E/t/3Z6o5UTgpvRDQqF1BERNRtwIXX9omD\nPcL8pfBGRKPS4o2IqFsKb0REjXKX4YiIeuUOFBERTXD7Km+pwitpC/AiMAm8UeI66mix5FG7pcXb\nn5Nsb6/gc6LdkkdtlLsMR0TUr40n18pOkmPgFkkbJa2aaQNJqyRtkLThdV4tebgYU8mjFtOO3h7j\npGyL93jbWyUdBNwq6RHb66duUExUPAGwrw5s4S8V0YPkUVuZVp5cK9Xitb21eN4GrAWOrSKoaJfk\nUbtVOC3kyOi78EpaJGmfna+Bk4GHqgos2iF5FP94gm2uxxgp09WwBFgraefnXG37plLRlJmvtNu+\nMcySRy2WCyjmyfYTwNEVxhItlDxqObuyidBHSYaTRUSz2ld3U3gjolnpaoiIqJOBdDVERNSsfXU3\nhTcimpWuhqaVucX1IG+P3W2IUcnhRzf/+IFZ153ytuWlPru1kke7GPY8yqiGiIg6jeHFEb1I4Y2I\nxnQuoGhf5U3hjYhmjdnMY71I4Y2IRqXFGxFRp5b28ZadCD0iooTOXA29PJog6fckbZb0qKRTZtnm\ng5Lul/SQpDWS5mzQpvBGRLPs3h4DJOnAGZYtA84G3g2cCvyppAXTtnkLsAY42/aRwJPAyrmOl66G\nskqO+zzlY132P67EB2d6w9HS1jxyNbf1kXQ4cBOwEfgXwMPAv7b9sy777AucA5wLfBf4/WmbnA5c\na/tV4G8lbaYzSf/dU7b5ReA12z8q3t8K/B7wtW7xpsUbEc2qrsX7LuBPbf9z4B+A35ppI0nHS1pN\np0gfAXzC9vSiC3AI8NSU908Xy6baDuwmaUXx/teAw+YKNIU3IprV+x0oFu+84WnxmH5j1Kdsf694\n/efA8dMPJekK4AbgFuCf2b5oSmt1/qHbptMd8SVJ9wIvApNz7ZeuhoholHb03New3faKLuunN4tn\naib/Nzqt4YuBUyX9T+D2ooBOt5VdW6+HFst2PYh9N3ACgKSTgX/aJUYgLd6IaJLpXEDRy2Nub5f0\nvuL1x4G73nQ4e4vt/wQsA64Ffgd4RNJvzPB564CzJe0p6QhgKXDv9I2Ku2MjaU/gc8CVcwWawhsR\njRFG7u3Rg0eB35b0N8ABwFdm29D2pO0bbX+MTmv1yRm2eRi4DvhrOifuftv2JICkGyW9rdj0wuKY\nm4AbbP+fuQJNV0NENKu6oWJv2P7E/A/vbcC2WdZ9AfjCDMs/MuX1hcCF8zlmCm9ENCuXDEdE1Ghn\nH2/Zj7G3AEeW/6R6pPBGRKPmMaphbKTwRkSDBn858DBK4Y2I5pgU3oiI2rWvpyGFNyKalYnQIyLq\nlsIbMxrkLb+jPZJHb2bDZPv6Gua8ZFjSVZK2SXpoyrIDJd0q6bHi+YDBhhmjLnkUsxqCidDr1stc\nDavpzL4+1UXAbbaXArcV7yO6WU3yKGaSwvtmttcDz01bfDqd211QPJ9RcVwxZpJHMSMDO9zbY4z0\n28e7xPYzxeufAEtm27CYrHgVwEL26vNwMaaSR61ncPv6eEufXLNtSbP+d2R7ApgA2FcHjtd/W1GZ\n5FFLmZxcm4dnJR0MUDzPOKVaxBySR5E+3nlYx89vYbwSuL6acKJlkkfRysI7Z1eDpGuAE+ncaO5p\nOvcqugy4TtK5dGZuP3OQQTau2y2uMzazJ8kjkkczGr+i2os5C6/tc2ZZ9aGKY4kxljyKGRnItJAR\nETVLizciok7tvGQ4hTcimmNwxvFGRNRszK5K60UKb0Q0K328Des23GZYjWLM424U/05GMeYq2BnV\nEBFRu7R4IyLqZDw52XQQtUvhjYjm7JwWsmVSeCOiWS0cTtbvJDkREaUZ8A739BgUSbdLWlG83iJp\n8cAOVkiLNyKa40yEHhFRu6pOrkm6EHjV9hWSvgQcbfuDkj4InAv8A3AM8AvAt2xfXMmB+4nVNQ7l\nkPRTOtP/7bQY2F5bAL1rQ1zvsP3Wij6rVsmj0oYmjyTdVMTTi4XAK1PeTxR3Jtn5WccBv2v71yXd\nCewJvB/4fTq3lvqm7eckLaBzc9XP2N4k6XbgAtsbJG0BVtge6N9brS3e6X9BkjbYXlFnDL1IXMMt\neVTOMMVle/qdp8vYCLxH0r7Aq8D9wArgBOAzwJnFvft2Aw4GlgGNXLmSroaIGAu2X5f0t8BvAt+n\nU1RPAt4J/D/gAuAY289LWk2nBd2IjGqIiHFyJ50Cu754/WngB8C+wMvAC5KWAB9uLEKaL7wTc2/S\niMQ1Wob155K46ncnnW6Eu20/S6dP+E7bP6RTgB8Brga+11yINZ9ci4iI5lu8ERGtk8IbEVGzRgqv\npFMlPSpps6SLmohhJsXlgg9KekDShgbjuErSNkkPTVl2oKRbJT1WPB/QVHzDInnUUyzJpSFUe+Et\nBi9/mc5ZxWXAOZKW1R1HFyfZXt7wOMfVwPTxjRcBt9leSmfw99AUmiYkj3q2muTS0GmixXsssNn2\nE7ZfA64FTm8gjqFlez3w3LTFpwNritdrgDNqDWr4JI96kFwaTk0U3kOAp6a8f7pYNgwM3CJpY3GF\nyzBZYvuZ4vVPgCVNBjMEkkf9Sy41LFeu7ep421slHQTcKumRosUwVGxbUsYBDq+RyCNILjWliRbv\nVuCwKe8PLZY1zvbW4nkbsJbOr7PD4llJBwMUz9sajqdpyaP+JZca1kThvQ9YKukISXsAZwPrGohj\nF5IWSdpn52vgZOCh7nvVah2wsni9Eri+wViGQfKof8mlhtXe1WD7DUnnATcDC4CrbD9cdxwzWAKs\nlQSdn8vVtm9qIhBJ1wAnAoslPQ1cDFwGXCfpXDpTIp7ZRGzDInnUm+TScMolwxERNcuVaxERNUvh\njYioWQpvRETNUngjImqWwhsRUbMU3oiImqXwRkTU7P8DDRZFvGyw8q8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108acb610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_policies(policies, threshold=0.9):\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    \n",
    "    for i in xrange(2):\n",
    "        for j in xrange(2):\n",
    "            policy = policies[2 * i + j]\n",
    "            rooms_map = -2 * env.occupancy\n",
    "            n_states = policy.weights.shape[0]\n",
    "            n_actions = 4\n",
    "            for s in xrange(n_states):\n",
    "                max_prob = np.max(policy.pmf([s]))\n",
    "                if max_prob > threshold:\n",
    "                    rooms_map[env.tocell[s]] = np.argmax(policy.pmf([s]))\n",
    "                else:\n",
    "                    rooms_map[env.tocell[s]] = -1\n",
    "            rooms_map[env.tocell[env.goal]] = 4\n",
    "            im = axs[i, j].imshow(rooms_map)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=axs.ravel().tolist())\n",
    "    labels = ['wall', 'p < {}'.format(threshold), 'up', 'down', 'left', 'right', 'goal']\n",
    "    cbar.ax.set_yticklabels(labels)\n",
    "    plt.show()\n",
    "\n",
    "visualize_policies(option_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp, expit\n",
    "\n",
    "n_states, n_actions = option_policies[0].weights.shape\n",
    "n_options = len(option_policies)\n",
    "gamma = 0.99\n",
    "threshold = 1e-12\n",
    "\n",
    "\"\"\" Compute P_env and R_env (known dynamics of environment) \"\"\"\n",
    "R_env = np.zeros((n_states, n_actions))\n",
    "R_env[54, 1] = 2./3\n",
    "R_env[54, 0] = R_env[54, 2:4] = 1./9\n",
    "R_env[70, 0] = 2./3\n",
    "R_env[70, 1:4] = 1./9\n",
    "\n",
    "P_env = np.zeros((n_states, n_actions, n_states))\n",
    "for r in xrange(13):\n",
    "    for c in xrange(13):\n",
    "        if env.occupancy[r, c] == 0:\n",
    "            for move in range(n_actions):\n",
    "                for a in xrange(n_actions):\n",
    "                    r_diff, c_diff = env.directions[move]\n",
    "                    r_new, c_new = r + r_diff, c + c_diff\n",
    "                    if a == move:\n",
    "                        if env.occupancy[r_new, c_new]:\n",
    "                            P_env[env.tostate[(r, c)], a, env.tostate[(r, c)]] += 2./3\n",
    "                        else:\n",
    "                            P_env[env.tostate[(r, c)], a, env.tostate[(r_new, c_new)]] += 2./3\n",
    "                    else:\n",
    "                        if env.occupancy[r_new, c_new]:\n",
    "                            P_env[env.tostate[(r, c)], a, env.tostate[(r, c)]] += 1./9\n",
    "                        else:\n",
    "                            P_env[env.tostate[(r, c)], a, env.tostate[(r_new, c_new)]] += 1./9                        \n",
    "\n",
    "\"\"\" Compute R and P (model of our options) by dynamic programming \"\"\"\n",
    "R = np.zeros((n_states, n_options))\n",
    "P = np.zeros((n_states, n_options, n_states))\n",
    "           \n",
    "def iterate():\n",
    "    for j in xrange(n_options):\n",
    "        # Compute pi \n",
    "        weights = option_policies[j].weights / temperature\n",
    "        pi = np.exp(weights - logsumexp(weights, axis=1, keepdims=True))\n",
    "        # Compute beta\n",
    "        beta = expit(option_terminations[j].weights)\n",
    "        # Update R\n",
    "        R[:, j] = (pi * (R_env + gamma * P_env.dot((1 - beta) * R[:, j]))).sum(axis=1)\n",
    "        # Update P\n",
    "        P[:, j, :] = (pi[:, :, np.newaxis] * gamma * (P_env * beta + (P_env * (1 - beta)).dot(P[:, j, :]))).sum(axis=1)\n",
    "\n",
    "R_old, P_old = np.copy(R), np.copy(P)\n",
    "iterate()\n",
    "while np.sum((R - R_old) ** 2) > threshold or np.sum((P - P_old) ** 2) > threshold:\n",
    "    R_old[:], P_old[:] = R, P\n",
    "    iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80135018  0.29390853  0.27525552  0.35707377]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1086e1d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980197942321\n",
      "[ 0.52713399  0.19333518  0.18105084  0.23488574]\n",
      "[ 0.52677437  0.18096871  0.18106509  0.13851844]\n"
     ]
    }
   ],
   "source": [
    "def visualize_rewards(R):\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    \n",
    "    for i in xrange(2):\n",
    "        for j in xrange(2):\n",
    "            rooms_map = -0.1 * env.occupancy\n",
    "            for s in xrange(n_states):\n",
    "                rooms_map[env.tocell[s]] = R[s, 2 * i + j]\n",
    "            im = axs[i, j].imshow(rooms_map) \n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "print np.max(R, axis=0)\n",
    "visualize_rewards(R)\n",
    "\n",
    "print P[0, 0, :].sum()\n",
    "print P[54, :, 62]\n",
    "print P[70, :, 62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6682243  0.         0.         0.       ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkA7BByCd/wceto8cs0YnTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10861e250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931653226468\n",
      "[ 0.61053851  0.          0.          0.        ]\n",
      "[ 0.6422364  0.         0.         0.       ]\n"
     ]
    }
   ],
   "source": [
    "print np.max(model_learning.R, axis=0)\n",
    "visualize_rewards(model_learning.R)\n",
    "\n",
    "print model_learning.P[0, 0, :].sum()\n",
    "print model_learning.P[54, :, 62]\n",
    "print model_learning.P[70, :, 62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmWU4GMzMLOP/AMPNTFOfkBZpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108861d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.plot(xrange(nepisodes), np.mean(history[:, :, 4], axis=0), label=\"Mean Error First Option\")\\nplt.plot(xrange(nepisodes), np.mean(history[:, :, 5], axis=0), label=\"Max Error First Option\")\\nplt.title(\"Probability Prediction Absolute Error\")\\nplt.xlabel(\"Episodes\")\\nplt.legend()\\nplt.show()\\n\\n\\nmean_R_error[run, episode] = np.mean(R_error, axis=0)\\n        mean_P_error[run, episode] = np.mean(P_error, axis=(0, 2)) \\n        max_R_error[run, episode] = np.max(R_error, axis=0)\\n        max_P_error[run, episode] = np.max(P_error, axis=(0, 2))\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(xrange(nepisodes), np.mean(mean_R_error[:, :, 0], axis=0), label=\"Mean Error Option 0\".format(i))\n",
    "plt.plot(xrange(nepisodes), np.mean(max_R_error[:, :, 0], axis=0), label=\"Max Error Option 0\".format(i))\n",
    "plt.title(\"Reward Prediction Absolute Error\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "plt.plot(xrange(nepisodes), np.mean(history[:, :, 4], axis=0), label=\"Mean Error First Option\")\n",
    "plt.plot(xrange(nepisodes), np.mean(history[:, :, 5], axis=0), label=\"Max Error First Option\")\n",
    "plt.title(\"Probability Prediction Absolute Error\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mean_R_error[run, episode] = np.mean(R_error, axis=0)\n",
    "        mean_P_error[run, episode] = np.mean(P_error, axis=(0, 2)) \n",
    "        max_R_error[run, episode] = np.max(R_error, axis=0)\n",
    "        max_P_error[run, episode] = np.max(P_error, axis=(0, 2))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
